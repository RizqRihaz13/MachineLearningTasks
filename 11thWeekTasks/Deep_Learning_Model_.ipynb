{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "oniP_wU8Fc31",
        "outputId": "c83ee3fc-754a-4142-891b-5e656e60e6f2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  slope  \\\n",
              "0   52    1   0       125   212    0        1      168      0      1.0      2   \n",
              "1   53    1   0       140   203    1        0      155      1      3.1      0   \n",
              "2   70    1   0       145   174    0        1      125      1      2.6      0   \n",
              "3   61    1   0       148   203    0        1      161      0      0.0      2   \n",
              "4   62    0   0       138   294    1        1      106      0      1.9      1   \n",
              "\n",
              "   ca  thal  target  \n",
              "0   2     3       0  \n",
              "1   0     3       0  \n",
              "2   0     3       0  \n",
              "3   1     3       0  \n",
              "4   3     2       0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4da7fea2-51c4-4d45-9d34-b32f93892b8d\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>sex</th>\n",
              "      <th>cp</th>\n",
              "      <th>trestbps</th>\n",
              "      <th>chol</th>\n",
              "      <th>fbs</th>\n",
              "      <th>restecg</th>\n",
              "      <th>thalach</th>\n",
              "      <th>exang</th>\n",
              "      <th>oldpeak</th>\n",
              "      <th>slope</th>\n",
              "      <th>ca</th>\n",
              "      <th>thal</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>52</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>125</td>\n",
              "      <td>212</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>168</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>53</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>140</td>\n",
              "      <td>203</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>155</td>\n",
              "      <td>1</td>\n",
              "      <td>3.1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>70</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>145</td>\n",
              "      <td>174</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>125</td>\n",
              "      <td>1</td>\n",
              "      <td>2.6</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>61</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>148</td>\n",
              "      <td>203</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>161</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>62</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>138</td>\n",
              "      <td>294</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>106</td>\n",
              "      <td>0</td>\n",
              "      <td>1.9</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4da7fea2-51c4-4d45-9d34-b32f93892b8d')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-4da7fea2-51c4-4d45-9d34-b32f93892b8d button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-4da7fea2-51c4-4d45-9d34-b32f93892b8d');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-e65760e4-9d06-4288-83e4-20d696d7707e\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-e65760e4-9d06-4288-83e4-20d696d7707e')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-e65760e4-9d06-4288-83e4-20d696d7707e button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "data",
              "summary": "{\n  \"name\": \"data\",\n  \"rows\": 1025,\n  \"fields\": [\n    {\n      \"column\": \"age\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 9,\n        \"min\": 29,\n        \"max\": 77,\n        \"num_unique_values\": 41,\n        \"samples\": [\n          65,\n          50,\n          54\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sex\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"cp\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 0,\n        \"max\": 3,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          1,\n          3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"trestbps\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 17,\n        \"min\": 94,\n        \"max\": 200,\n        \"num_unique_values\": 49,\n        \"samples\": [\n          128,\n          172\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"chol\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 51,\n        \"min\": 126,\n        \"max\": 564,\n        \"num_unique_values\": 152,\n        \"samples\": [\n          267,\n          262\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"fbs\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"restecg\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 2,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"thalach\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 23,\n        \"min\": 71,\n        \"max\": 202,\n        \"num_unique_values\": 91,\n        \"samples\": [\n          180,\n          152\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"exang\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"oldpeak\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.175053255150173,\n        \"min\": 0.0,\n        \"max\": 6.2,\n        \"num_unique_values\": 40,\n        \"samples\": [\n          2.8,\n          0.4\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"slope\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 2,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          2,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ca\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 0,\n        \"max\": 4,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0,\n          4\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"thal\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 3,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          2,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"target\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Memuat dataset\n",
        "file_path = '/content/heart.csv'\n",
        "data = pd.read_csv(file_path)\n",
        "\n",
        "# Menampilkan beberapa baris pertama untuk memahami struktur data\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dataset berhasil dimuat dan memiliki beberapa kolom dengan informasi terkait karakteristik pasien (seperti usia, jenis kelamin, tekanan darah, dll.) serta kolom target yang menunjukkan apakah pasien memiliki penyakit jantung (0: tidak, 1: ya)"
      ],
      "metadata": {
        "id": "2DhsdxG3VEoq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Langkah berikutnya adalah mengecek apakah ada nilai yang hilang di dataset ini**"
      ],
      "metadata": {
        "id": "_7v5weOlVLfH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Mengecek kembali apakah ada nilai yang hilang dalam dataset\n",
        "missing_values = dataset.isnull().sum()\n",
        "\n",
        "# Menampilkan jumlah nilai yang hilang untuk setiap kolom\n",
        "missing_values"
      ],
      "metadata": {
        "id": "v4gs30FzH-NM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 523
        },
        "outputId": "bdd0fb3c-6841-416c-e413-939923fb22b7"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "age         0\n",
              "sex         0\n",
              "cp          0\n",
              "trestbps    0\n",
              "chol        0\n",
              "fbs         0\n",
              "restecg     0\n",
              "thalach     0\n",
              "exang       0\n",
              "oldpeak     0\n",
              "slope       0\n",
              "ca          0\n",
              "thal        0\n",
              "target      0\n",
              "dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>age</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sex</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>cp</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>trestbps</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>chol</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>fbs</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>restecg</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>thalach</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>exang</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>oldpeak</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>slope</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ca</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>thal</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>target</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dataset tidak memiliki nilai yang hilang pada kolom manapun, sehingga kita dapat langsung melanjutkan ke langkah preprocessing data. Berikutnya, kita akan membagi dataset menjadi fitur (input) dan target (output), serta melakukan normalisasi fitur untuk memastikan pelatihan model lebih stabil."
      ],
      "metadata": {
        "id": "xXwOax4YV6Jc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Memisahkan fitur (X) dan target (y)\n",
        "X = dataset.drop('target', axis=1)\n",
        "y = dataset['target']\n",
        "\n",
        "# Membagi data menjadi set pelatihan dan pengujian (80:20)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "# Normalisasi fitur dengan StandardScaler\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Menampilkan dimensi dataset setelah pembagian\n",
        "X_train.shape, X_test.shape, y_train.shape, y_test.shape\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1O01MmmPPm_K",
        "outputId": "ecd9efd5-31b9-4f02-c7ac-3ed44fc35290"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((820, 13), (205, 13), (820,), (205,))"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dataset telah berhasil dibagi menjadi data pelatihan (80%) dan pengujian (20%). Data fitur telah dinormalisasi menggunakan StandardScaler untuk memastikan setiap fitur memiliki mean 0 dan standar deviasi 1. Berikut dimensi dataset:\n",
        "\n",
        "X_train: 820 sampel, 13 fitur.\n",
        "\n",
        "X_test: 205 sampel, 13 fitur.\n",
        "\n",
        "y_train dan y_test: masing-masing target yang sesuai."
      ],
      "metadata": {
        "id": "0o6HXP4VWEK9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Langkah selanjutnya adalah mendefinisikan model MLP menggunakan PyTorch.**"
      ],
      "metadata": {
        "id": "bpncq_nhXBBD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "# Konversi data menjadi tensor PyTorch\n",
        "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
        "y_train_tensor = torch.tensor(y_train.values, dtype=torch.long)\n",
        "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
        "y_test_tensor = torch.tensor(y_test.values, dtype=torch.long)\n",
        "\n",
        "# Membuat DataLoader untuk batch processing\n",
        "batch_size = 32\n",
        "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
        "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "# Mendefinisikan arsitektur model MLP\n",
        "class MLPModel(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        super(MLPModel, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_size, hidden_size)  # Layer input ke hidden\n",
        "        self.relu = nn.ReLU()  # Aktivasi ReLU\n",
        "        self.fc2 = nn.Linear(hidden_size, hidden_size)  # Layer hidden ke hidden\n",
        "        self.fc3 = nn.Linear(hidden_size, output_size)  # Layer hidden ke output\n",
        "        self.softmax = nn.Softmax(dim=1)  # Aktivasi softmax untuk output\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc1(x)  # Masukkan ke layer pertama\n",
        "        x = self.relu(x)  # Aktivasi ReLU\n",
        "        x = self.fc2(x)  # Masukkan ke layer kedua\n",
        "        x = self.relu(x)  # Aktivasi ReLU\n",
        "        x = self.fc3(x)  # Masukkan ke layer output\n",
        "        return x  # Output logits\n",
        "\n",
        "# Parameter model\n",
        "input_size = X_train.shape[1]  # Jumlah fitur\n",
        "hidden_size = 64  # Jumlah unit pada hidden layer\n",
        "output_size = 2  # Jumlah kelas (0 dan 1)\n",
        "\n",
        "# Inisialisasi model\n",
        "model = MLPModel(input_size, hidden_size, output_size)\n",
        "\n",
        "# Fungsi loss dan optimizer\n",
        "criterion = nn.CrossEntropyLoss()  # Loss untuk klasifikasi\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)  # Optimizer Adam\n",
        "\n",
        "# Menampilkan arsitektur model\n",
        "model\n"
      ],
      "metadata": {
        "id": "gcSdJQeDJX72",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dac74969-86f1-42a1-a0c6-ea8b7ec9358f"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MLPModel(\n",
              "  (fc1): Linear(in_features=13, out_features=64, bias=True)\n",
              "  (relu): ReLU()\n",
              "  (fc2): Linear(in_features=64, out_features=64, bias=True)\n",
              "  (fc3): Linear(in_features=64, out_features=2, bias=True)\n",
              "  (softmax): Softmax(dim=1)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model MLP ini terdiri dari 3 layer utama:\n",
        "\n",
        "Input layer (fc1): Menerima 13 fitur dan menghasilkan 64 neuron.\n",
        "\n",
        "Hidden layer (fc2): Memproses 64 neuron menjadi 64 neuron dengan aktivasi ReLU.\n",
        "\n",
        "Output layer (fc3): Menghasilkan 2 kelas (output) menggunakan Softmax untuk probabilitas.\n",
        "\n",
        "Struktur ini cukup sederhana untuk dataset ukuran kecil-menengah. ReLU menambah non-linearitas, sementara output Softmax memastikan hasil berupa probabilitas."
      ],
      "metadata": {
        "id": "gQmuxBPHW393"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Bandingkan Hidden Layer (1,2,3) dengan jumlah neuron (4, 8, 16, 32, 64,...)**"
      ],
      "metadata": {
        "id": "jzjBB-v8b553"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "from sklearn.metrics import accuracy_score\n",
        "import pandas as pd\n",
        "\n",
        "# Fungsi untuk membuat model MLP dengan parameter fleksibel\n",
        "class FlexibleMLP(nn.Module):\n",
        "    def __init__(self, input_size, hidden_sizes, output_size):\n",
        "        super(FlexibleMLP, self).__init__()\n",
        "        self.hidden_layers = nn.ModuleList()  # List untuk menyimpan hidden layers\n",
        "        prev_size = input_size  # Ukuran input awal\n",
        "        for hidden_size in hidden_sizes:\n",
        "            self.hidden_layers.append(nn.Linear(prev_size, hidden_size))\n",
        "            prev_size = hidden_size\n",
        "        self.output_layer = nn.Linear(prev_size, output_size)  # Output layer\n",
        "\n",
        "    def forward(self, x):\n",
        "        for layer in self.hidden_layers:\n",
        "            x = F.relu(layer(x))  # Aktivasi ReLU untuk setiap hidden layer\n",
        "        x = self.output_layer(x)  # Layer output tanpa aktivasi softmax (digunakan dalam CrossEntropyLoss)\n",
        "        return x\n",
        "\n",
        "# Fungsi untuk melatih model dan mengukur akurasi\n",
        "def train_and_evaluate(hidden_layers, neurons_per_layer):\n",
        "    # Inisialisasi model dengan konfigurasi tertentu\n",
        "    model = FlexibleMLP(input_size=X_train.shape[1], hidden_sizes=[neurons_per_layer] * hidden_layers, output_size=2)\n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    # Pelatihan model\n",
        "    epochs = 10  # Kurangi epoch untuk mempercepat eksperimen\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        for inputs, labels in train_loader:\n",
        "            optimizer.zero_grad()  # Reset gradient\n",
        "            outputs = model(inputs)  # Forward pass\n",
        "            loss = criterion(outputs, labels)  # Hitung loss\n",
        "            loss.backward()  # Backward pass\n",
        "            optimizer.step()  # Update bobot model\n",
        "\n",
        "    # Evaluasi model pada data pengujian\n",
        "    model.eval()\n",
        "    predictions = []\n",
        "    with torch.no_grad():\n",
        "        for inputs, _ in test_loader:\n",
        "            outputs = model(inputs)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            predictions.extend(predicted.cpu().numpy())\n",
        "\n",
        "    # Mengukur akurasi\n",
        "    acc = accuracy_score(y_test, predictions)\n",
        "    return acc\n",
        "\n",
        "# Parameter eksperimen\n",
        "hidden_layer_options = [1, 2, 3]  # Jumlah hidden layers\n",
        "neurons_per_layer_options = [4, 8, 16, 32, 64]  # Jumlah neuron per layer\n",
        "\n",
        "# Menyimpan hasil eksperimen\n",
        "results = []\n",
        "\n",
        "# Looping untuk setiap kombinasi jumlah hidden layers dan jumlah neuron\n",
        "for hidden_layers in hidden_layer_options:\n",
        "    for neurons_per_layer in neurons_per_layer_options:\n",
        "        acc = train_and_evaluate(hidden_layers, neurons_per_layer)\n",
        "        results.append({\"Hidden Layers\": hidden_layers, \"Neurons per Layer\": neurons_per_layer, \"Accuracy\": acc})\n",
        "\n",
        "# Menyimpan hasil dalam DataFrame untuk analisis\n",
        "results_df = pd.DataFrame(results)\n",
        "\n",
        "# Menampilkan hasil eksperimen sebagai tabel\n",
        "print(results_df)\n",
        "\n",
        "# Menyimpan hasil ke file CSV untuk analisis lebih lanjut\n",
        "results_df.to_csv(\"hasil_perbandingan_hidden_layers.csv\", index=False)\n",
        "\n",
        "# Jika Anda di Google Colab, unduh file CSV\n",
        "from google.colab import files\n",
        "files.download(\"hasil_perbandingan_hidden_layers.csv\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "uJ8aNi1tXI25",
        "outputId": "132fcb55-5b05-40ef-eb09-482ada4629a4"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    Hidden Layers  Neurons per Layer  Accuracy\n",
            "0               1                  4  0.834146\n",
            "1               1                  8  0.780488\n",
            "2               1                 16  0.824390\n",
            "3               1                 32  0.858537\n",
            "4               1                 64  0.843902\n",
            "5               2                  4  0.848780\n",
            "6               2                  8  0.819512\n",
            "7               2                 16  0.848780\n",
            "8               2                 32  0.848780\n",
            "9               2                 64  0.878049\n",
            "10              3                  4  0.839024\n",
            "11              3                  8  0.843902\n",
            "12              3                 16  0.873171\n",
            "13              3                 32  0.897561\n",
            "14              3                 64  0.951220\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_23145c51-62ad-44d4-bc69-2d7a885dec4f\", \"hasil_perbandingan_hidden_layers.csv\", 391)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1.Pengaruh Jumlah Hidden Layers**\n",
        "\n",
        "**1 Hidden Layer:**\n",
        "\n",
        "*   Akurasi bervariasi dari 0.780488 hingga 0.858537 saat jumlah neuron meningkat.\n",
        "*   Meskipun akurasi meningkat saat jumlah neuron bertambah, performanya terbatas dibandingkan konfigurasi dengan lebih banyak hidden layer.\n",
        "\n",
        "**2 Hidden Layers:**\n",
        "\n",
        "*   Akurasi meningkat dibandingkan dengan konfigurasi 1 hidden layer, mulai dari 0.819512 hingga 0.878049.\n",
        "*   Model lebih mampu menangkap pola data karena memiliki representasi yang lebih kompleks.\n",
        "\n",
        "**3 Hidden Layers:**\n",
        "\n",
        "*   Memberikan hasil terbaik dengan akurasi tertinggi mencapai 0.951220 saat jumlah neuron adalah 64.\n",
        "*   Dengan lebih banyak hidden layer, model memiliki kapasitas lebih besar untuk mempelajari pola data yang kompleks.\n",
        "\n",
        "**2.Pengaruh Jumlah Neuron per Layer**\n",
        "\n",
        "*   Pada setiap jumlah hidden layer, penambahan jumlah neuron cenderung meningkatkan akurasi hingga titik tertentu.\n",
        "*   64 neuron per layer memberikan hasil terbaik di semua konfigurasi, terutama pada model dengan 3 hidden layers.\n",
        "\n",
        "**3.Konfigurasi Optimal**\n",
        "\n",
        "*   3 Hidden Layers dengan 64 Neuron per Layer memberikan akurasi tertinggi (0.951220).\n",
        "*    Ini menunjukkan bahwa model dengan lebih banyak layer dan neuron lebih baik dalam menangkap pola yang kompleks pada dataset ini.\n",
        "\n",
        "**4.Trade-Offs**\n",
        "\n",
        "\n",
        "*   Model dengan 3 hidden layers dan lebih banyak neuron memerlukan lebih banyak waktu pelatihan dan sumber daya komputasi.\n",
        "*   Jika sumber daya terbatas, 2 Hidden Layers dengan 32 atau 64 Neuron per Layer adalah alternatif yang baik karena memberikan akurasi tinggi (0.878049) dengan kompleksitas lebih rendah.\n",
        "\n",
        "**Rekomendasi:**\n",
        "\n",
        "\n",
        "*   Gunakan 3 Hidden Layers dengan 64 Neuron per Layer untuk performa terbaik jika sumber daya mendukung.\n",
        "*   Untuk efisiensi, pilih 2 Hidden Layers dengan 32 Neuron per Layer, yang masih memberikan akurasi tinggi tanpa terlalu membebani komputasi.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "k6TK3-zCZUaa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Bandingkan Activation Function (linear,Sigmoid,RelU,Softmax,Tanh)**"
      ],
      "metadata": {
        "id": "VkHueA13b4Bm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from sklearn.metrics import accuracy_score\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Data Preprocessing\n",
        "dataset = pd.read_csv(\"heart.csv\")\n",
        "X = dataset.drop(\"target\", axis=1)\n",
        "y = dataset[\"target\"]\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
        "y_train_tensor = torch.tensor(y_train.values, dtype=torch.long)\n",
        "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
        "y_test_tensor = torch.tensor(y_test.values, dtype=torch.long)\n",
        "batch_size = 32\n",
        "train_loader = DataLoader(TensorDataset(X_train_tensor, y_train_tensor), batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(TensorDataset(X_test_tensor, y_test_tensor), batch_size=batch_size, shuffle=False)\n",
        "\n",
        "# Definisi Model Flexible dengan Fungsi Aktivasi\n",
        "class ActivationComparisonMLP(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size, activation_fn):\n",
        "        super(ActivationComparisonMLP, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
        "        self.fc2 = nn.Linear(hidden_size, hidden_size)\n",
        "        self.fc3 = nn.Linear(hidden_size, output_size)\n",
        "        self.activation_fn = activation_fn\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.activation_fn(self.fc1(x))\n",
        "        x = self.activation_fn(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "# Fungsi untuk melatih model dan mengukur akurasi\n",
        "def train_and_evaluate_activation(activation_fn):\n",
        "    model = ActivationComparisonMLP(input_size=X_train.shape[1], hidden_size=32, output_size=2, activation_fn=activation_fn)\n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    # Pelatihan model\n",
        "    for epoch in range(10):\n",
        "        model.train()\n",
        "        for inputs, labels in train_loader:\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "    # Evaluasi model\n",
        "    model.eval()\n",
        "    predictions = []\n",
        "    with torch.no_grad():\n",
        "        for inputs, _ in test_loader:\n",
        "            outputs = model(inputs)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            predictions.extend(predicted.cpu().numpy())\n",
        "\n",
        "    # Mengukur akurasi\n",
        "    return accuracy_score(y_test, predictions)\n",
        "\n",
        "# Membandingkan berbagai fungsi aktivasi\n",
        "activation_functions = {\n",
        "    \"Linear\": lambda x: x,\n",
        "    \"Sigmoid\": torch.sigmoid,\n",
        "    \"ReLU\": F.relu,\n",
        "    \"Softmax\": lambda x: F.softmax(x, dim=1),\n",
        "    \"Tanh\": torch.tanh\n",
        "}\n",
        "\n",
        "results = []\n",
        "for name, activation_fn in activation_functions.items():\n",
        "    accuracy = train_and_evaluate_activation(activation_fn)\n",
        "    results.append({\"Activation Function\": name, \"Accuracy\": accuracy})\n",
        "\n",
        "# Menampilkan hasil\n",
        "results_df = pd.DataFrame(results)\n",
        "print(results_df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xOiC_qJibNRH",
        "outputId": "f25cdc8f-3ff3-4281-b480-e3caa2cdfd4e"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Activation Function  Accuracy\n",
            "0              Linear  0.814634\n",
            "1             Sigmoid  0.804878\n",
            "2                ReLU  0.873171\n",
            "3             Softmax  0.756098\n",
            "4                Tanh  0.834146\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Kesimpulan:**\n",
        "\n",
        "ReLU adalah fungsi aktivasi terbaik pada eksperimen ini, menghasilkan akurasi tertinggi (0.873171).\n",
        "\n",
        "Tanh adalah alternatif yang baik untuk data terpusat, tetapi sedikit kalah dengan ReLU.\n",
        "\n",
        "Sigmoid dan Softmax memiliki performa yang lebih rendah karena masalah saturasi dan tidak optimal untuk hidden layers.\n",
        "\n",
        "Linear hanya memberikan performa dasar tanpa manfaat non-linearitas.\n",
        "\n",
        "**Rekomendasi:**\n",
        "\n",
        "Gunakan ReLU untuk hidden layers pada sebagian besar kasus karena kinerjanya yang cepat dan stabil. Hindari penggunaan Softmax di hidden layers, karena lebih cocok untuk output layer pada klasifikasi multi-kelas. Jika data sangat terpusat, Tanh bisa menjadi alternatif."
      ],
      "metadata": {
        "id": "uZtYN_LhcRS8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Bandingkan Epoch (1,10,25,50,100,250)**"
      ],
      "metadata": {
        "id": "pgmPrcAVeEes"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from sklearn.metrics import accuracy_score\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Data Preprocessing\n",
        "dataset = pd.read_csv(\"heart.csv\")  # Pastikan dataset \"heart.csv\" tersedia\n",
        "X = dataset.drop(\"target\", axis=1)\n",
        "y = dataset[\"target\"]\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
        "y_train_tensor = torch.tensor(y_train.values, dtype=torch.long)\n",
        "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
        "y_test_tensor = torch.tensor(y_test.values, dtype=torch.long)\n",
        "train_loader = DataLoader(TensorDataset(X_train_tensor, y_train_tensor), batch_size=32, shuffle=True)\n",
        "test_loader = DataLoader(TensorDataset(X_test_tensor, y_test_tensor), batch_size=32, shuffle=False)\n",
        "\n",
        "# Definisi Model\n",
        "class SimpleMLP(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        super(SimpleMLP, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_size, hidden_size)  # Layer pertama\n",
        "        self.fc2 = nn.Linear(hidden_size, hidden_size)  # Layer kedua\n",
        "        self.fc3 = nn.Linear(hidden_size, output_size)  # Layer output\n",
        "        self.relu = nn.ReLU()  # Aktivasi ReLU\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.relu(self.fc1(x))  # Aktivasi setelah layer pertama\n",
        "        x = self.relu(self.fc2(x))  # Aktivasi setelah layer kedua\n",
        "        x = self.fc3(x)  # Output tanpa aktivasi softmax (CrossEntropyLoss akan menangani ini)\n",
        "        return x\n",
        "\n",
        "# Fungsi Pelatihan dan Evaluasi\n",
        "def train_and_evaluate_epochs(num_epochs):\n",
        "    # Inisialisasi model, optimizer, dan loss function\n",
        "    model = SimpleMLP(input_size=X_train.shape[1], hidden_size=32, output_size=2)\n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    # Pelatihan model\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        for inputs, labels in train_loader:\n",
        "            optimizer.zero_grad()  # Reset gradient\n",
        "            outputs = model(inputs)  # Forward pass\n",
        "            loss = criterion(outputs, labels)  # Hitung loss\n",
        "            loss.backward()  # Backward pass\n",
        "            optimizer.step()  # Update bobot model\n",
        "\n",
        "    # Evaluasi model\n",
        "    model.eval()\n",
        "    predictions = []\n",
        "    with torch.no_grad():\n",
        "        for inputs, _ in test_loader:\n",
        "            outputs = model(inputs)\n",
        "            _, predicted = torch.max(outputs, 1)  # Prediksi kelas dengan probabilitas tertinggi\n",
        "            predictions.extend(predicted.cpu().numpy())\n",
        "\n",
        "    # Menghitung akurasi\n",
        "    return accuracy_score(y_test, predictions)\n",
        "\n",
        "# Membandingkan berbagai epoch\n",
        "epoch_options = [1, 10, 25, 50, 100, 250]\n",
        "results = []\n",
        "\n",
        "for epochs in epoch_options:\n",
        "    accuracy = train_and_evaluate_epochs(epochs)\n",
        "    results.append({\"Epochs\": epochs, \"Accuracy\": accuracy})\n",
        "\n",
        "# Menampilkan hasil\n",
        "results_df = pd.DataFrame(results)\n",
        "print(results_df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5TmPvb5DcZDq",
        "outputId": "2a5e2fee-5874-41d3-ab6c-3e151fe43037"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Epochs  Accuracy\n",
            "0       1  0.800000\n",
            "1      10  0.843902\n",
            "2      25  0.941463\n",
            "3      50  1.000000\n",
            "4     100  1.000000\n",
            "5     250  1.000000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Kesimpulan:**\n",
        "\n",
        "Akurasi meningkat seiring bertambahnya jumlah epoch hingga mencapai konvergensi pada 50 epoch.\n",
        "\n",
        "Setelah 50 epoch, model sudah cukup terlatih, dan penambahan epoch tidak meningkatkan akurasi.\n",
        "\n",
        "Epoch yang terlalu sedikit (1 atau 10) tidak cukup untuk melatih model secara optimal.\n",
        "\n",
        "50 epoch adalah titik optimal untuk pelatihan pada dataset ini, karena mencapai akurasi maksimal dengan efisiensi pelatihan.\n",
        "\n",
        "**Rekomendasi:**\n",
        "\n",
        "Gunakan 50 epoch sebagai jumlah epoch yang optimal untuk pelatihan model ini, karena sudah cukup untuk mencapai akurasi sempurna.\n",
        "Hindari penggunaan epoch terlalu tinggi (>100) kecuali diperlukan untuk dataset yang lebih kompleks, karena dapat membuang waktu komputasi."
      ],
      "metadata": {
        "id": "fz1-arPhd8NQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Bandingkan Learning Rate (10/1/0.1/0.01/0.001/0.0001)**"
      ],
      "metadata": {
        "id": "xNpEA1PxeIIh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from sklearn.metrics import accuracy_score\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Data Preprocessing\n",
        "dataset = pd.read_csv(\"heart.csv\")  # Pastikan dataset \"heart.csv\" tersedia\n",
        "X = dataset.drop(\"target\", axis=1)\n",
        "y = dataset[\"target\"]\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
        "y_train_tensor = torch.tensor(y_train.values, dtype=torch.long)\n",
        "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
        "y_test_tensor = torch.tensor(y_test.values, dtype=torch.long)\n",
        "train_loader = DataLoader(TensorDataset(X_train_tensor, y_train_tensor), batch_size=32, shuffle=True)\n",
        "test_loader = DataLoader(TensorDataset(X_test_tensor, y_test_tensor), batch_size=32, shuffle=False)\n",
        "\n",
        "# Definisi Model\n",
        "class SimpleMLP(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        super(SimpleMLP, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_size, hidden_size)  # Layer pertama\n",
        "        self.fc2 = nn.Linear(hidden_size, hidden_size)  # Layer kedua\n",
        "        self.fc3 = nn.Linear(hidden_size, output_size)  # Layer output\n",
        "        self.relu = nn.ReLU()  # Aktivasi ReLU\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.relu(self.fc1(x))  # Aktivasi setelah layer pertama\n",
        "        x = self.relu(self.fc2(x))  # Aktivasi setelah layer kedua\n",
        "        x = self.fc3(x)  # Output tanpa aktivasi softmax (CrossEntropyLoss akan menangani ini)\n",
        "        return x\n",
        "\n",
        "# Fungsi Pelatihan dan Evaluasi\n",
        "def train_and_evaluate_lr(learning_rate):\n",
        "    # Inisialisasi model, optimizer, dan loss function\n",
        "    model = SimpleMLP(input_size=X_train.shape[1], hidden_size=32, output_size=2)\n",
        "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)  # Optimizer dengan learning rate spesifik\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    # Pelatihan model\n",
        "    for epoch in range(50):  # Tetapkan jumlah epoch untuk semua eksperimen\n",
        "        model.train()\n",
        "        for inputs, labels in train_loader:\n",
        "            optimizer.zero_grad()  # Reset gradient\n",
        "            outputs = model(inputs)  # Forward pass\n",
        "            loss = criterion(outputs, labels)  # Hitung loss\n",
        "            loss.backward()  # Backward pass\n",
        "            optimizer.step()  # Update bobot model\n",
        "\n",
        "    # Evaluasi model\n",
        "    model.eval()\n",
        "    predictions = []\n",
        "    with torch.no_grad():\n",
        "        for inputs, _ in test_loader:\n",
        "            outputs = model(inputs)\n",
        "            _, predicted = torch.max(outputs, 1)  # Prediksi kelas dengan probabilitas tertinggi\n",
        "            predictions.extend(predicted.cpu().numpy())\n",
        "\n",
        "    # Menghitung akurasi\n",
        "    return accuracy_score(y_test, predictions)\n",
        "\n",
        "# Membandingkan berbagai learning rate\n",
        "learning_rate_options = [10, 1, 0.1, 0.01, 0.001, 0.0001]  # Daftar nilai learning rate\n",
        "results = []\n",
        "\n",
        "for lr in learning_rate_options:\n",
        "    accuracy = train_and_evaluate_lr(lr)  # Melatih model dengan learning rate tertentu\n",
        "    results.append({\"Learning Rate\": lr, \"Accuracy\": accuracy})  # Simpan hasil\n",
        "\n",
        "# Menampilkan hasil\n",
        "results_df = pd.DataFrame(results)\n",
        "print(results_df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rvyxbIeqeBzx",
        "outputId": "1f63a319-e1d5-4bf2-9fa6-3850aba77c09"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Learning Rate  Accuracy\n",
            "0        10.0000  0.580488\n",
            "1         1.0000  0.531707\n",
            "2         0.1000  0.751220\n",
            "3         0.0100  1.000000\n",
            "4         0.0010  0.990244\n",
            "5         0.0001  0.848780\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Kesimpulan:**\n",
        "\n",
        "Learning Rate = 0.01 adalah yang terbaik untuk eksperimen ini, menghasilkan akurasi sempurna 1.000000.\n",
        "\n",
        "Learning Rate yang terlalu besar (10.0, 1.0) menyebabkan model gagal belajar (divergensi).\n",
        "\n",
        "Learning Rate yang terlalu kecil (0.0001) membuat proses pembelajaran terlalu lambat dan tidak optimal.\n",
        "\n",
        "0.001 adalah alternatif yang baik jika stabilitas lebih diutamakan.\n",
        "\n",
        "**Rekomendasi:**\n",
        "\n",
        "Gunakan Learning Rate = 0.01 untuk performa optimal.\n",
        "\n",
        "Jika dataset lebih kompleks atau model lebih besar, pertimbangkan 0.001 untuk stabilitas, meskipun memerlukan lebih banyak epoch untuk mencapai konvergensi."
      ],
      "metadata": {
        "id": "rD_dnw3gevxu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Bandingkan Batch Size (16,32,64,128,256,512)**"
      ],
      "metadata": {
        "id": "xbtTU1TBe1yK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from sklearn.metrics import accuracy_score\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Data Preprocessing\n",
        "dataset = pd.read_csv(\"heart.csv\")  # Pastikan dataset \"heart.csv\" tersedia\n",
        "X = dataset.drop(\"target\", axis=1)\n",
        "y = dataset[\"target\"]\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
        "y_train_tensor = torch.tensor(y_train.values, dtype=torch.long)\n",
        "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
        "y_test_tensor = torch.tensor(y_test.values, dtype=torch.long)\n",
        "\n",
        "# Definisi Model\n",
        "class SimpleMLP(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        super(SimpleMLP, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_size, hidden_size)  # Layer pertama\n",
        "        self.fc2 = nn.Linear(hidden_size, hidden_size)  # Layer kedua\n",
        "        self.fc3 = nn.Linear(hidden_size, output_size)  # Layer output\n",
        "        self.relu = nn.ReLU()  # Aktivasi ReLU\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.relu(self.fc1(x))  # Aktivasi setelah layer pertama\n",
        "        x = self.relu(self.fc2(x))  # Aktivasi setelah layer kedua\n",
        "        x = self.fc3(x)  # Output tanpa aktivasi softmax (CrossEntropyLoss akan menangani ini)\n",
        "        return x\n",
        "\n",
        "# Fungsi Pelatihan dan Evaluasi\n",
        "def train_and_evaluate_batch_size(batch_size):\n",
        "    # Membuat DataLoader dengan batch size yang berbeda\n",
        "    train_loader = DataLoader(TensorDataset(X_train_tensor, y_train_tensor), batch_size=batch_size, shuffle=True)\n",
        "    test_loader = DataLoader(TensorDataset(X_test_tensor, y_test_tensor), batch_size=batch_size, shuffle=False)\n",
        "\n",
        "    # Inisialisasi model, optimizer, dan loss function\n",
        "    model = SimpleMLP(input_size=X_train.shape[1], hidden_size=32, output_size=2)\n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.01)  # Learning rate tetap\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    # Pelatihan model\n",
        "    for epoch in range(50):  # Tetapkan jumlah epoch tetap\n",
        "        model.train()\n",
        "        for inputs, labels in train_loader:\n",
        "            optimizer.zero_grad()  # Reset gradient\n",
        "            outputs = model(inputs)  # Forward pass\n",
        "            loss = criterion(outputs, labels)  # Hitung loss\n",
        "            loss.backward()  # Backward pass\n",
        "            optimizer.step()  # Update bobot model\n",
        "\n",
        "    # Evaluasi model\n",
        "    model.eval()\n",
        "    predictions = []\n",
        "    with torch.no_grad():\n",
        "        for inputs, _ in test_loader:\n",
        "            outputs = model(inputs)\n",
        "            _, predicted = torch.max(outputs, 1)  # Prediksi kelas dengan probabilitas tertinggi\n",
        "            predictions.extend(predicted.cpu().numpy())\n",
        "\n",
        "    # Menghitung akurasi\n",
        "    return accuracy_score(y_test, predictions)\n",
        "\n",
        "# Membandingkan berbagai batch size\n",
        "batch_size_options = [16, 32, 64, 128, 256, 512]  # Daftar batch size\n",
        "results = []\n",
        "\n",
        "for batch_size in batch_size_options:\n",
        "    accuracy = train_and_evaluate_batch_size(batch_size)  # Melatih model dengan batch size tertentu\n",
        "    results.append({\"Batch Size\": batch_size, \"Accuracy\": accuracy})  # Simpan hasil\n",
        "\n",
        "# Menampilkan hasil\n",
        "results_df = pd.DataFrame(results)\n",
        "print(results_df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nwnGmB1GfQrc",
        "outputId": "fb977e56-3186-49bd-a4a4-5e3fae6e666d"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Batch Size  Accuracy\n",
            "0          16       1.0\n",
            "1          32       1.0\n",
            "2          64       1.0\n",
            "3         128       1.0\n",
            "4         256       1.0\n",
            "5         512       1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Kesimpulan:**\n",
        "\n",
        "Batch size tidak memengaruhi akurasi dalam eksperimen ini karena model mencapai akurasi sempurna di semua konfigurasi.\n",
        "\n",
        "Batch size yang optimal tergantung pada sumber daya komputasi:\n",
        "Gunakan batch size besar (128 atau 256) untuk pelatihan lebih cepat jika memori GPU cukup.\n",
        "\n",
        "Gunakan batch size kecil (16 atau 32) jika memori terbatas atau untuk dataset yang sangat bervariasi.\n",
        "\n",
        "**Rekomendasi:**\n",
        "\n",
        "Pilih batch size sesuai kapasitas hardware (GPU/CPU). Untuk kasus ini, Batch Size = 128 adalah kompromi terbaik antara efisiensi dan kecepatan pelatihan.\n",
        "\n",
        "Jika dataset lebih kompleks atau lebih besar, batch size yang lebih besar (256 atau 512) bisa lebih efisien dengan memanfaatkan GPU.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "CQV2EUQlfotB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Bandingkan Hidden Layer, Activation Function, Epoch, Learning Rate, Batch Size**"
      ],
      "metadata": {
        "id": "kWs6Ts3Of_7F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "\n",
        "# Data Preprocessing\n",
        "dataset = pd.read_csv(\"heart.csv\")  # Pastikan dataset \"heart.csv\" tersedia\n",
        "X = dataset.drop(\"target\", axis=1)\n",
        "y = dataset[\"target\"]\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
        "y_train_tensor = torch.tensor(y_train.values, dtype=torch.long)\n",
        "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
        "y_test_tensor = torch.tensor(y_test.values, dtype=torch.long)\n",
        "\n",
        "# Definisi Model\n",
        "class FlexibleMLP(nn.Module):\n",
        "    def __init__(self, input_size, hidden_sizes, output_size, activation_fn):\n",
        "        super(FlexibleMLP, self).__init__()\n",
        "        self.hidden_layers = nn.ModuleList()\n",
        "        prev_size = input_size\n",
        "        for hidden_size in hidden_sizes:\n",
        "            self.hidden_layers.append(nn.Linear(prev_size, hidden_size))\n",
        "            prev_size = hidden_size\n",
        "        self.output_layer = nn.Linear(prev_size, output_size)\n",
        "        self.activation_fn = activation_fn\n",
        "\n",
        "    def forward(self, x):\n",
        "        for layer in self.hidden_layers:\n",
        "            x = self.activation_fn(layer(x))\n",
        "        x = self.output_layer(x)\n",
        "        return x\n",
        "\n",
        "# Fungsi Pelatihan dan Evaluasi\n",
        "def train_and_evaluate(hidden_layers, activation_fn, epochs, learning_rate, batch_size):\n",
        "    # Membuat DataLoader dengan batch size yang diberikan\n",
        "    train_loader = DataLoader(TensorDataset(X_train_tensor, y_train_tensor), batch_size=batch_size, shuffle=True)\n",
        "    test_loader = DataLoader(TensorDataset(X_test_tensor, y_test_tensor), batch_size=batch_size, shuffle=False)\n",
        "\n",
        "    # Inisialisasi model\n",
        "    model = FlexibleMLP(input_size=X_train.shape[1], hidden_sizes=[32] * hidden_layers, output_size=2, activation_fn=activation_fn)\n",
        "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    # Pelatihan model\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        for inputs, labels in train_loader:\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "    # Evaluasi model\n",
        "    model.eval()\n",
        "    predictions = []\n",
        "    with torch.no_grad():\n",
        "        for inputs, _ in test_loader:\n",
        "            outputs = model(inputs)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            predictions.extend(predicted.cpu().numpy())\n",
        "\n",
        "    # Menghitung akurasi\n",
        "    return accuracy_score(y_test, predictions)\n",
        "\n",
        "# Parameter yang akan dibandingkan\n",
        "hidden_layer_options = [1, 2, 3]\n",
        "activation_functions = {\n",
        "    \"ReLU\": F.relu,\n",
        "    \"Sigmoid\": torch.sigmoid,\n",
        "    \"Tanh\": torch.tanh\n",
        "}\n",
        "epoch_options = [10, 50]\n",
        "learning_rate_options = [0.01, 0.001]\n",
        "batch_size_options = [32, 128]\n",
        "\n",
        "# Menyimpan hasil eksperimen\n",
        "results = []\n",
        "\n",
        "# Looping untuk semua kombinasi parameter\n",
        "for hidden_layers in hidden_layer_options:\n",
        "    for activation_name, activation_fn in activation_functions.items():\n",
        "        for epochs in epoch_options:\n",
        "            for learning_rate in learning_rate_options:\n",
        "                for batch_size in batch_size_options:\n",
        "                    accuracy = train_and_evaluate(hidden_layers, activation_fn, epochs, learning_rate, batch_size)\n",
        "                    results.append({\n",
        "                        \"Hidden Layers\": hidden_layers,\n",
        "                        \"Activation Function\": activation_name,\n",
        "                        \"Epochs\": epochs,\n",
        "                        \"Learning Rate\": learning_rate,\n",
        "                        \"Batch Size\": batch_size,\n",
        "                        \"Accuracy\": accuracy\n",
        "                    })\n",
        "\n",
        "# Menampilkan hasil\n",
        "results_df = pd.DataFrame(results)\n",
        "print(results_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hgJQ7ZSfgAPU",
        "outputId": "4277e1a3-6469-4f7d-9c8f-f58f5ea58b59"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    Hidden Layers Activation Function  Epochs  Learning Rate  Batch Size  \\\n",
            "0               1                ReLU      10          0.010          32   \n",
            "1               1                ReLU      10          0.010         128   \n",
            "2               1                ReLU      10          0.001          32   \n",
            "3               1                ReLU      10          0.001         128   \n",
            "4               1                ReLU      50          0.010          32   \n",
            "..            ...                 ...     ...            ...         ...   \n",
            "67              3                Tanh      10          0.001         128   \n",
            "68              3                Tanh      50          0.010          32   \n",
            "69              3                Tanh      50          0.010         128   \n",
            "70              3                Tanh      50          0.001          32   \n",
            "71              3                Tanh      50          0.001         128   \n",
            "\n",
            "    Accuracy  \n",
            "0   0.960976  \n",
            "1   0.892683  \n",
            "2   0.829268  \n",
            "3   0.824390  \n",
            "4   1.000000  \n",
            "..       ...  \n",
            "67  0.848780  \n",
            "68  1.000000  \n",
            "69  1.000000  \n",
            "70  0.990244  \n",
            "71  0.897561  \n",
            "\n",
            "[72 rows x 6 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Kesimpulan dari Hasil Eksperimen:**\n",
        "Hidden Layers:\n",
        "\n",
        "1 Hidden Layer: Memberikan performa yang baik pada kombinasi parameter optimal, tetapi kurang fleksibel untuk pola yang lebih kompleks.\n",
        "\n",
        "2 Hidden Layers: Lebih stabil dan secara konsisten memberikan akurasi tinggi di berbagai kombinasi parameter.\n",
        "\n",
        "3 Hidden Layers: Memberikan akurasi tertinggi pada data yang lebih kompleks, tetapi memerlukan lebih banyak sumber daya komputasi dan tuning parameter.\n",
        "Activation Function:\n",
        "\n",
        "ReLU adalah fungsi aktivasi terbaik secara keseluruhan, memberikan akurasi tertinggi secara konsisten dengan stabilitas yang baik.\n",
        "\n",
        "Tanh: Alternatif yang baik pada beberapa kombinasi, tetapi kurang stabil dibandingkan ReLU.\n",
        "\n",
        "Sigmoid: Tidak optimal karena masalah saturasi dan gradien yang menghilang, sering memberikan akurasi lebih rendah dibandingkan ReLU.\n",
        "\n",
        "Epochs:\n",
        "\n",
        "10 Epochs: Tidak cukup untuk melatih model secara optimal, menghasilkan akurasi yang lebih rendah.\n",
        "\n",
        "50 Epochs: Memberikan akurasi maksimal pada sebagian besar kombinasi parameter, cukup untuk mencapai konvergensi.\n",
        "\n",
        "Learning Rate:\n",
        "\n",
        "0.01: Memberikan hasil terbaik pada sebagian besar kombinasi parameter.\n",
        "\n",
        "0.001: Stabil, tetapi memerlukan lebih banyak epoch untuk mencapai performa maksimal.\n",
        "\n",
        "Batch Size:\n",
        "\n",
        "Batch size 32 dan 128 memberikan hasil yang konsisten baik tanpa memengaruhi akurasi secara signifikan.\n",
        "\n",
        "Batch size lebih kecil memungkinkan pembaruan model lebih sering tetapi membutuhkan lebih banyak iterasi.\n",
        "\n",
        "**Rekomendasi Akhir:**\n",
        "Gunakan 2 atau 3 hidden layers untuk fleksibilitas dan performa yang lebih baik pada pola data yang kompleks.\n",
        "\n",
        "Gunakan ReLU sebagai fungsi aktivasi utama karena memberikan stabilitas dan performa tertinggi.\n",
        "\n",
        "Pilih 50 epochs untuk memastikan model terlatih secara optimal.\n",
        "\n",
        "Gunakan learning rate = 0.01 untuk mencapai performa maksimal dengan stabilitas.\n",
        "\n",
        "Pilih batch size 32 atau 128 sesuai dengan sumber daya komputasi yang tersedia."
      ],
      "metadata": {
        "id": "H7Vuex8TgoeR"
      }
    }
  ]
}