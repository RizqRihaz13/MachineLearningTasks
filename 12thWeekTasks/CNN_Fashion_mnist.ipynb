{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "6bItvXb-Pblx"
      },
      "outputs": [],
      "source": [
        "# Import library yang dibutuhkan\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from sklearn.model_selection import ParameterGrid\n",
        "from torch.optim.lr_scheduler import StepLR, ReduceLROnPlateau\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Persiapan Data CIFAR-10\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])\n",
        "\n",
        "# Download dataset CIFAR-10\n",
        "train_dataset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "test_dataset = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "# Dataloader untuk batching data\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FNFBZNFKPmWH",
        "outputId": "84d11659-b681-4163-8f43-c3c75c5095a8"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170M/170M [00:08<00:00, 20.9MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Definisikan model CNN dengan variasi kernel dan pooling\n",
        "class CNNModel(nn.Module):\n",
        "    def __init__(self, kernel_size=3, pooling='max'):\n",
        "        super(CNNModel, self).__init__()\n",
        "        # Memilih pooling (MaxPooling atau AveragePooling)\n",
        "        pool_layer = nn.MaxPool2d if pooling == 'max' else nn.AvgPool2d\n",
        "\n",
        "        # Layer konvolusi pertama\n",
        "        self.conv1 = nn.Conv2d(3, 32, kernel_size=kernel_size, stride=1, padding=kernel_size//2)\n",
        "        self.pool1 = pool_layer(2, 2)\n",
        "\n",
        "        # Layer konvolusi kedua\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=kernel_size, stride=1, padding=kernel_size//2)\n",
        "        self.pool2 = pool_layer(2, 2)\n",
        "\n",
        "        # Fully connected layers\n",
        "        self.fc1 = nn.Linear(64 * 8 * 8, 128)\n",
        "        self.fc2 = nn.Linear(128, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool1(torch.relu(self.conv1(x)))  # Konvolusi pertama diikuti pooling\n",
        "        x = self.pool2(torch.relu(self.conv2(x)))  # Konvolusi kedua diikuti pooling\n",
        "        x = x.view(-1, 64 * 8 * 8)               # Flatten tensor untuk fully connected layer\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "8b3f9oIzRh-i"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Fungsi Training dan Evaluasi Model\n",
        "def train_model(model, train_loader, optimizer, criterion, scheduler=None, early_stop_patience=10, epochs=100):\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    model.to(device)\n",
        "\n",
        "    best_loss = float('inf')\n",
        "    patience = 0\n",
        "    train_losses = []\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        epoch_loss = 0\n",
        "\n",
        "        for images, labels in train_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()  # Reset gradien optimizer\n",
        "            outputs = model(images)  # Forward pass\n",
        "            loss = criterion(outputs, labels)  # Hitung loss\n",
        "            loss.backward()  # Backward pass\n",
        "            optimizer.step()  # Update bobot\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "\n",
        "        epoch_loss /= len(train_loader)\n",
        "        train_losses.append(epoch_loss)\n",
        "\n",
        "        if scheduler:\n",
        "            scheduler.step(epoch_loss)  # Update learning rate jika menggunakan scheduler\n",
        "\n",
        "        print(f\"Epoch {epoch+1}/{epochs}, Loss: {epoch_loss:.4f}\")\n",
        "\n",
        "        # Early Stopping\n",
        "        if epoch_loss < best_loss:\n",
        "            best_loss = epoch_loss\n",
        "            patience = 0\n",
        "        else:\n",
        "            patience += 1\n",
        "            if patience >= early_stop_patience:\n",
        "                print(\"Early stopping triggered\")\n",
        "                break\n",
        "\n",
        "    return train_losses\n",
        "\n",
        "def evaluate_model(model, test_loader, criterion):\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in test_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            test_loss += loss.item()\n",
        "            preds = outputs.argmax(dim=1, keepdim=True)\n",
        "            correct += preds.eq(labels.view_as(preds)).sum().item()\n",
        "\n",
        "    test_loss /= len(test_loader)\n",
        "    accuracy = 100. * correct / len(test_loader.dataset)\n",
        "\n",
        "    print(f\"Test Loss: {test_loss:.4f}, Accuracy: {accuracy:.2f}%\")\n",
        "    return test_loss, accuracy\n"
      ],
      "metadata": {
        "id": "VXf5PMf2Rk2_"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. Eksperimen Parameter\n",
        "params = {\n",
        "    'kernel_size': [3, 5, 7],\n",
        "    'pooling': ['max', 'avg'],\n",
        "    'epochs': [5, 50, 100],\n",
        "    'optimizer': ['SGD', 'RMSProp', 'Adam']\n",
        "}\n",
        "\n",
        "results = []\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "param_grid = list(ParameterGrid(params))\n",
        "\n",
        "for param in param_grid:\n",
        "    print(f\"Training model with parameters: {param}\")\n",
        "\n",
        "    # Definisikan model dan optimizer\n",
        "    model = CNNModel(kernel_size=param['kernel_size'], pooling=param['pooling'])\n",
        "    optimizer = optim.SGD(model.parameters(), lr=0.01) if param['optimizer'] == 'SGD' else (\n",
        "                optim.RMSprop(model.parameters(), lr=0.01) if param['optimizer'] == 'RMSProp' else\n",
        "                optim.Adam(model.parameters(), lr=0.01))\n",
        "\n",
        "    scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=3)  # Scheduler untuk LR\n",
        "\n",
        "    # Training model\n",
        "    start_time = time.time()\n",
        "    train_losses = train_model(model, train_loader, optimizer, criterion, scheduler=scheduler, epochs=param['epochs'])\n",
        "    end_time = time.time()\n",
        "\n",
        "    # Evaluasi model\n",
        "    test_loss, accuracy = evaluate_model(model, test_loader, criterion)\n",
        "\n",
        "    results.append({\n",
        "        'params': param,\n",
        "        'test_loss': test_loss,\n",
        "        'accuracy': accuracy,\n",
        "        'training_time': end_time - start_time\n",
        "    })\n",
        "\n",
        "    # Visualisasi training loss per epoch\n",
        "    plt.plot(train_losses, label=f\"{param}\")\n",
        "\n",
        "plt.legend()\n",
        "plt.title(\"Training Loss per Experiment\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.show()\n",
        "\n",
        "# Tampilkan hasil eksperimen\n",
        "import pandas as pd\n",
        "results_df = pd.DataFrame(results)\n",
        "import ace_tools as tools; tools.display_dataframe_to_user(name=\"Hasil Eksperimen CNN CIFAR10\", dataframe=results_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "iyuFg9BRRoUl",
        "outputId": "738a987f-bb2c-4a33-bb62-6e990fdbeeb8"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training model with parameters: {'epochs': 5, 'kernel_size': 3, 'optimizer': 'SGD', 'pooling': 'max'}\n",
            "Epoch 1/5, Loss: 2.0490\n",
            "Epoch 2/5, Loss: 1.6658\n",
            "Epoch 3/5, Loss: 1.4731\n",
            "Epoch 4/5, Loss: 1.3499\n",
            "Epoch 5/5, Loss: 1.2653\n",
            "Test Loss: 1.3153, Accuracy: 53.57%\n",
            "Training model with parameters: {'epochs': 5, 'kernel_size': 3, 'optimizer': 'SGD', 'pooling': 'avg'}\n",
            "Epoch 1/5, Loss: 2.1633\n",
            "Epoch 2/5, Loss: 1.8038\n",
            "Epoch 3/5, Loss: 1.6578\n",
            "Epoch 4/5, Loss: 1.5524\n",
            "Epoch 5/5, Loss: 1.4696\n",
            "Test Loss: 1.4601, Accuracy: 47.33%\n",
            "Training model with parameters: {'epochs': 5, 'kernel_size': 3, 'optimizer': 'RMSProp', 'pooling': 'max'}\n",
            "Epoch 1/5, Loss: 9.4435\n",
            "Epoch 2/5, Loss: 1.5288\n",
            "Epoch 3/5, Loss: 1.3706\n",
            "Epoch 4/5, Loss: 1.2528\n",
            "Epoch 5/5, Loss: 1.2787\n",
            "Test Loss: 1.4018, Accuracy: 52.01%\n",
            "Training model with parameters: {'epochs': 5, 'kernel_size': 3, 'optimizer': 'RMSProp', 'pooling': 'avg'}\n",
            "Epoch 1/5, Loss: 6.8019\n",
            "Epoch 2/5, Loss: 1.5826\n",
            "Epoch 3/5, Loss: 1.3947\n",
            "Epoch 4/5, Loss: 1.2065\n",
            "Epoch 5/5, Loss: 1.1363\n",
            "Test Loss: 1.5682, Accuracy: 51.01%\n",
            "Training model with parameters: {'epochs': 5, 'kernel_size': 3, 'optimizer': 'Adam', 'pooling': 'max'}\n",
            "Epoch 1/5, Loss: 1.8285\n",
            "Epoch 2/5, Loss: 1.6802\n",
            "Epoch 3/5, Loss: 1.6211\n",
            "Epoch 4/5, Loss: 1.5566\n",
            "Epoch 5/5, Loss: 1.5157\n",
            "Test Loss: 1.5075, Accuracy: 44.69%\n",
            "Training model with parameters: {'epochs': 5, 'kernel_size': 3, 'optimizer': 'Adam', 'pooling': 'avg'}\n",
            "Epoch 1/5, Loss: 1.7279\n",
            "Epoch 2/5, Loss: 1.5200\n",
            "Epoch 3/5, Loss: 1.4565\n",
            "Epoch 4/5, Loss: 1.4304\n",
            "Epoch 5/5, Loss: 1.3945\n",
            "Test Loss: 1.4416, Accuracy: 48.29%\n",
            "Training model with parameters: {'epochs': 5, 'kernel_size': 5, 'optimizer': 'SGD', 'pooling': 'max'}\n",
            "Epoch 1/5, Loss: 2.0003\n",
            "Epoch 2/5, Loss: 1.6045\n",
            "Epoch 3/5, Loss: 1.4279\n",
            "Epoch 4/5, Loss: 1.3248\n",
            "Epoch 5/5, Loss: 1.2387\n",
            "Test Loss: 1.2388, Accuracy: 55.71%\n",
            "Training model with parameters: {'epochs': 5, 'kernel_size': 5, 'optimizer': 'SGD', 'pooling': 'avg'}\n",
            "Epoch 1/5, Loss: 2.0763\n",
            "Epoch 2/5, Loss: 1.7353\n",
            "Epoch 3/5, Loss: 1.5745\n",
            "Epoch 4/5, Loss: 1.4615\n",
            "Epoch 5/5, Loss: 1.3763\n",
            "Test Loss: 1.3526, Accuracy: 50.91%\n",
            "Training model with parameters: {'epochs': 5, 'kernel_size': 5, 'optimizer': 'RMSProp', 'pooling': 'max'}\n",
            "Epoch 1/5, Loss: 16.0925\n",
            "Epoch 2/5, Loss: 2.1515\n",
            "Epoch 3/5, Loss: 1.9911\n",
            "Epoch 4/5, Loss: 1.7577\n",
            "Epoch 5/5, Loss: 1.6911\n",
            "Test Loss: 2.3128, Accuracy: 33.59%\n",
            "Training model with parameters: {'epochs': 5, 'kernel_size': 5, 'optimizer': 'RMSProp', 'pooling': 'avg'}\n",
            "Epoch 1/5, Loss: 9.1693\n",
            "Epoch 2/5, Loss: 1.9946\n",
            "Epoch 3/5, Loss: 1.6374\n",
            "Epoch 4/5, Loss: 1.5500\n",
            "Epoch 5/5, Loss: 1.4456\n",
            "Test Loss: 1.4495, Accuracy: 50.37%\n",
            "Training model with parameters: {'epochs': 5, 'kernel_size': 5, 'optimizer': 'Adam', 'pooling': 'max'}\n",
            "Epoch 1/5, Loss: 2.0368\n",
            "Epoch 2/5, Loss: 1.7411\n",
            "Epoch 3/5, Loss: 1.6082\n",
            "Epoch 4/5, Loss: 1.5348\n",
            "Epoch 5/5, Loss: 1.4905\n",
            "Test Loss: 1.5210, Accuracy: 45.86%\n",
            "Training model with parameters: {'epochs': 5, 'kernel_size': 5, 'optimizer': 'Adam', 'pooling': 'avg'}\n",
            "Epoch 1/5, Loss: 1.9551\n",
            "Epoch 2/5, Loss: 1.6958\n",
            "Epoch 3/5, Loss: 1.6228\n",
            "Epoch 4/5, Loss: 1.5674\n",
            "Epoch 5/5, Loss: 1.5251\n",
            "Test Loss: 1.5412, Accuracy: 44.92%\n",
            "Training model with parameters: {'epochs': 5, 'kernel_size': 7, 'optimizer': 'SGD', 'pooling': 'max'}\n",
            "Epoch 1/5, Loss: 1.9785\n",
            "Epoch 2/5, Loss: 1.5690\n",
            "Epoch 3/5, Loss: 1.4069\n",
            "Epoch 4/5, Loss: 1.2973\n",
            "Epoch 5/5, Loss: 1.2049\n",
            "Test Loss: 1.2198, Accuracy: 56.48%\n",
            "Training model with parameters: {'epochs': 5, 'kernel_size': 7, 'optimizer': 'SGD', 'pooling': 'avg'}\n",
            "Epoch 1/5, Loss: 2.0641\n",
            "Epoch 2/5, Loss: 1.6932\n",
            "Epoch 3/5, Loss: 1.5201\n",
            "Epoch 4/5, Loss: 1.4206\n",
            "Epoch 5/5, Loss: 1.3531\n",
            "Test Loss: 1.3933, Accuracy: 50.08%\n",
            "Training model with parameters: {'epochs': 5, 'kernel_size': 7, 'optimizer': 'RMSProp', 'pooling': 'max'}\n",
            "Epoch 1/5, Loss: 68.3909\n",
            "Epoch 2/5, Loss: 2.2256\n",
            "Epoch 3/5, Loss: 2.3139\n",
            "Epoch 4/5, Loss: 2.1963\n",
            "Epoch 5/5, Loss: 2.2453\n",
            "Test Loss: 2.2365, Accuracy: 14.31%\n",
            "Training model with parameters: {'epochs': 5, 'kernel_size': 7, 'optimizer': 'RMSProp', 'pooling': 'avg'}\n",
            "Epoch 1/5, Loss: 44.2807\n",
            "Epoch 2/5, Loss: 2.1866\n",
            "Epoch 3/5, Loss: 1.9594\n",
            "Epoch 4/5, Loss: 1.8727\n",
            "Epoch 5/5, Loss: 1.8323\n",
            "Test Loss: 1.8571, Accuracy: 30.46%\n",
            "Training model with parameters: {'epochs': 5, 'kernel_size': 7, 'optimizer': 'Adam', 'pooling': 'max'}\n",
            "Epoch 1/5, Loss: 2.0801\n",
            "Epoch 2/5, Loss: 1.9097\n",
            "Epoch 3/5, Loss: 1.8570\n",
            "Epoch 4/5, Loss: 1.8294\n",
            "Epoch 5/5, Loss: 1.8050\n",
            "Test Loss: 1.7642, Accuracy: 35.13%\n",
            "Training model with parameters: {'epochs': 5, 'kernel_size': 7, 'optimizer': 'Adam', 'pooling': 'avg'}\n",
            "Epoch 1/5, Loss: 1.9732\n",
            "Epoch 2/5, Loss: 1.7546\n",
            "Epoch 3/5, Loss: 1.7018\n",
            "Epoch 4/5, Loss: 1.6601\n",
            "Epoch 5/5, Loss: 1.6319\n",
            "Test Loss: 1.6113, Accuracy: 40.33%\n",
            "Training model with parameters: {'epochs': 50, 'kernel_size': 3, 'optimizer': 'SGD', 'pooling': 'max'}\n",
            "Epoch 1/50, Loss: 2.0515\n",
            "Epoch 2/50, Loss: 1.6988\n",
            "Epoch 3/50, Loss: 1.5133\n",
            "Epoch 4/50, Loss: 1.3933\n",
            "Epoch 5/50, Loss: 1.3051\n",
            "Epoch 6/50, Loss: 1.2323\n",
            "Epoch 7/50, Loss: 1.1716\n",
            "Epoch 8/50, Loss: 1.1129\n",
            "Epoch 9/50, Loss: 1.0622\n",
            "Epoch 10/50, Loss: 1.0146\n",
            "Epoch 11/50, Loss: 0.9698\n",
            "Epoch 12/50, Loss: 0.9286\n",
            "Epoch 13/50, Loss: 0.8887\n",
            "Epoch 14/50, Loss: 0.8537\n",
            "Epoch 15/50, Loss: 0.8205\n",
            "Epoch 16/50, Loss: 0.7887\n",
            "Epoch 17/50, Loss: 0.7570\n",
            "Epoch 18/50, Loss: 0.7270\n",
            "Epoch 19/50, Loss: 0.6980\n",
            "Epoch 20/50, Loss: 0.6689\n",
            "Epoch 21/50, Loss: 0.6402\n",
            "Epoch 22/50, Loss: 0.6114\n",
            "Epoch 23/50, Loss: 0.5820\n",
            "Epoch 24/50, Loss: 0.5564\n",
            "Epoch 25/50, Loss: 0.5274\n",
            "Epoch 26/50, Loss: 0.4985\n",
            "Epoch 27/50, Loss: 0.4739\n",
            "Epoch 28/50, Loss: 0.4457\n",
            "Epoch 29/50, Loss: 0.4182\n",
            "Epoch 30/50, Loss: 0.3889\n",
            "Epoch 31/50, Loss: 0.3644\n",
            "Epoch 32/50, Loss: 0.3407\n",
            "Epoch 33/50, Loss: 0.3139\n",
            "Epoch 34/50, Loss: 0.2874\n",
            "Epoch 35/50, Loss: 0.2658\n",
            "Epoch 36/50, Loss: 0.2441\n",
            "Epoch 37/50, Loss: 0.2191\n",
            "Epoch 38/50, Loss: 0.1949\n",
            "Epoch 39/50, Loss: 0.1743\n",
            "Epoch 40/50, Loss: 0.1561\n",
            "Epoch 41/50, Loss: 0.1373\n",
            "Epoch 42/50, Loss: 0.1208\n",
            "Epoch 43/50, Loss: 0.1096\n",
            "Epoch 44/50, Loss: 0.0877\n",
            "Epoch 45/50, Loss: 0.0731\n",
            "Epoch 46/50, Loss: 0.0624\n",
            "Epoch 47/50, Loss: 0.0525\n",
            "Epoch 48/50, Loss: 0.0422\n",
            "Epoch 49/50, Loss: 0.0342\n",
            "Epoch 50/50, Loss: 0.0266\n",
            "Test Loss: 1.6647, Accuracy: 69.24%\n",
            "Training model with parameters: {'epochs': 50, 'kernel_size': 3, 'optimizer': 'SGD', 'pooling': 'avg'}\n",
            "Epoch 1/50, Loss: 2.1372\n",
            "Epoch 2/50, Loss: 1.8004\n",
            "Epoch 3/50, Loss: 1.6524\n",
            "Epoch 4/50, Loss: 1.5512\n",
            "Epoch 5/50, Loss: 1.4769\n",
            "Epoch 6/50, Loss: 1.4202\n",
            "Epoch 7/50, Loss: 1.3736\n",
            "Epoch 8/50, Loss: 1.3335\n",
            "Epoch 9/50, Loss: 1.2988\n",
            "Epoch 10/50, Loss: 1.2615\n",
            "Epoch 11/50, Loss: 1.2268\n",
            "Epoch 12/50, Loss: 1.1919\n",
            "Epoch 13/50, Loss: 1.1590\n",
            "Epoch 14/50, Loss: 1.1274\n",
            "Epoch 15/50, Loss: 1.0958\n",
            "Epoch 16/50, Loss: 1.0664\n",
            "Epoch 17/50, Loss: 1.0391\n",
            "Epoch 18/50, Loss: 1.0123\n",
            "Epoch 19/50, Loss: 0.9858\n",
            "Epoch 20/50, Loss: 0.9597\n",
            "Epoch 21/50, Loss: 0.9350\n",
            "Epoch 22/50, Loss: 0.9100\n",
            "Epoch 23/50, Loss: 0.8865\n",
            "Epoch 24/50, Loss: 0.8632\n",
            "Epoch 25/50, Loss: 0.8420\n",
            "Epoch 26/50, Loss: 0.8189\n",
            "Epoch 27/50, Loss: 0.7966\n",
            "Epoch 28/50, Loss: 0.7753\n",
            "Epoch 29/50, Loss: 0.7551\n",
            "Epoch 30/50, Loss: 0.7336\n",
            "Epoch 31/50, Loss: 0.7112\n",
            "Epoch 32/50, Loss: 0.6923\n",
            "Epoch 33/50, Loss: 0.6692\n",
            "Epoch 34/50, Loss: 0.6500\n",
            "Epoch 35/50, Loss: 0.6300\n",
            "Epoch 36/50, Loss: 0.6101\n",
            "Epoch 37/50, Loss: 0.5871\n",
            "Epoch 38/50, Loss: 0.5673\n",
            "Epoch 39/50, Loss: 0.5466\n",
            "Epoch 40/50, Loss: 0.5277\n",
            "Epoch 41/50, Loss: 0.5076\n",
            "Epoch 42/50, Loss: 0.4868\n",
            "Epoch 43/50, Loss: 0.4672\n",
            "Epoch 44/50, Loss: 0.4500\n",
            "Epoch 45/50, Loss: 0.4256\n",
            "Epoch 46/50, Loss: 0.4095\n",
            "Epoch 47/50, Loss: 0.3902\n",
            "Epoch 48/50, Loss: 0.3726\n",
            "Epoch 49/50, Loss: 0.3510\n",
            "Epoch 50/50, Loss: 0.3350\n",
            "Test Loss: 1.2218, Accuracy: 65.83%\n",
            "Training model with parameters: {'epochs': 50, 'kernel_size': 3, 'optimizer': 'RMSProp', 'pooling': 'max'}\n",
            "Epoch 1/50, Loss: 6.3766\n",
            "Epoch 2/50, Loss: 1.6214\n",
            "Epoch 3/50, Loss: 1.4189\n",
            "Epoch 4/50, Loss: 1.2959\n",
            "Epoch 5/50, Loss: 1.2256\n",
            "Epoch 6/50, Loss: 1.1599\n",
            "Epoch 7/50, Loss: 1.1133\n",
            "Epoch 8/50, Loss: 1.0715\n",
            "Epoch 9/50, Loss: 1.0447\n",
            "Epoch 10/50, Loss: 1.0145\n",
            "Epoch 11/50, Loss: 0.9876\n",
            "Epoch 12/50, Loss: 0.9615\n",
            "Epoch 13/50, Loss: 0.9368\n",
            "Epoch 14/50, Loss: 0.9187\n",
            "Epoch 15/50, Loss: 0.9070\n",
            "Epoch 16/50, Loss: 0.8975\n",
            "Epoch 17/50, Loss: 0.8780\n",
            "Epoch 18/50, Loss: 0.8828\n",
            "Epoch 19/50, Loss: 0.8547\n",
            "Epoch 20/50, Loss: 0.8532\n",
            "Epoch 21/50, Loss: 0.8451\n",
            "Epoch 22/50, Loss: 0.8361\n",
            "Epoch 23/50, Loss: 0.8439\n",
            "Epoch 24/50, Loss: 0.8376\n",
            "Epoch 25/50, Loss: 0.8418\n",
            "Epoch 26/50, Loss: 0.8457\n",
            "Epoch 27/50, Loss: 0.5443\n",
            "Epoch 28/50, Loss: 0.4810\n",
            "Epoch 29/50, Loss: 0.4511\n",
            "Epoch 30/50, Loss: 0.4284\n",
            "Epoch 31/50, Loss: 0.4111\n",
            "Epoch 32/50, Loss: 0.3960\n",
            "Epoch 33/50, Loss: 0.3817\n",
            "Epoch 34/50, Loss: 0.3683\n",
            "Epoch 35/50, Loss: 0.3569\n",
            "Epoch 36/50, Loss: 0.3446\n",
            "Epoch 37/50, Loss: 0.3357\n",
            "Epoch 38/50, Loss: 0.3257\n",
            "Epoch 39/50, Loss: 0.3173\n",
            "Epoch 40/50, Loss: 0.3093\n",
            "Epoch 41/50, Loss: 0.3005\n",
            "Epoch 42/50, Loss: 0.2934\n",
            "Epoch 43/50, Loss: 0.2861\n",
            "Epoch 44/50, Loss: 0.2800\n",
            "Epoch 45/50, Loss: 0.2734\n",
            "Epoch 46/50, Loss: 0.2679\n",
            "Epoch 47/50, Loss: 0.2624\n",
            "Epoch 48/50, Loss: 0.2582\n",
            "Epoch 49/50, Loss: 0.2529\n",
            "Epoch 50/50, Loss: 0.2475\n",
            "Test Loss: 3.9331, Accuracy: 62.12%\n",
            "Training model with parameters: {'epochs': 50, 'kernel_size': 3, 'optimizer': 'RMSProp', 'pooling': 'avg'}\n",
            "Epoch 1/50, Loss: 7.9359\n",
            "Epoch 2/50, Loss: 1.5318\n",
            "Epoch 3/50, Loss: 1.2976\n",
            "Epoch 4/50, Loss: 1.2360\n",
            "Epoch 5/50, Loss: 1.1041\n",
            "Epoch 6/50, Loss: 1.0176\n",
            "Epoch 7/50, Loss: 0.9658\n",
            "Epoch 8/50, Loss: 0.9286\n",
            "Epoch 9/50, Loss: 0.8607\n",
            "Epoch 10/50, Loss: 0.8381\n",
            "Epoch 11/50, Loss: 0.8182\n",
            "Epoch 12/50, Loss: 0.7620\n",
            "Epoch 13/50, Loss: 0.7234\n",
            "Epoch 14/50, Loss: 0.6890\n",
            "Epoch 15/50, Loss: 0.6569\n",
            "Epoch 16/50, Loss: 0.6534\n",
            "Epoch 17/50, Loss: 0.6151\n",
            "Epoch 18/50, Loss: 0.6163\n",
            "Epoch 19/50, Loss: 0.5772\n",
            "Epoch 20/50, Loss: 0.5644\n",
            "Epoch 21/50, Loss: 0.5552\n",
            "Epoch 22/50, Loss: 0.5367\n",
            "Epoch 23/50, Loss: 0.5238\n",
            "Epoch 24/50, Loss: 0.5220\n",
            "Epoch 25/50, Loss: 0.5142\n",
            "Epoch 26/50, Loss: 0.5000\n",
            "Epoch 27/50, Loss: 0.4951\n",
            "Epoch 28/50, Loss: 0.4839\n",
            "Epoch 29/50, Loss: 0.4751\n",
            "Epoch 30/50, Loss: 0.4681\n",
            "Epoch 31/50, Loss: 0.4723\n",
            "Epoch 32/50, Loss: 0.4537\n",
            "Epoch 33/50, Loss: 0.4710\n",
            "Epoch 34/50, Loss: 0.4467\n",
            "Epoch 35/50, Loss: 0.4471\n",
            "Epoch 36/50, Loss: 0.4331\n",
            "Epoch 37/50, Loss: 0.4349\n",
            "Epoch 38/50, Loss: 0.4337\n",
            "Epoch 39/50, Loss: 0.4328\n",
            "Epoch 40/50, Loss: 0.4237\n",
            "Epoch 41/50, Loss: 0.4321\n",
            "Epoch 42/50, Loss: 0.4201\n",
            "Epoch 43/50, Loss: 0.4739\n",
            "Epoch 44/50, Loss: 0.4206\n",
            "Epoch 45/50, Loss: 0.4164\n",
            "Epoch 46/50, Loss: 0.4507\n",
            "Epoch 47/50, Loss: 0.4245\n",
            "Epoch 48/50, Loss: 0.4174\n",
            "Epoch 49/50, Loss: 0.5169\n",
            "Epoch 50/50, Loss: 0.1941\n",
            "Test Loss: 3.7897, Accuracy: 61.53%\n",
            "Training model with parameters: {'epochs': 50, 'kernel_size': 3, 'optimizer': 'Adam', 'pooling': 'max'}\n",
            "Epoch 1/50, Loss: 1.6810\n",
            "Epoch 2/50, Loss: 1.4769\n",
            "Epoch 3/50, Loss: 1.4142\n",
            "Epoch 4/50, Loss: 1.3785\n",
            "Epoch 5/50, Loss: 1.3507\n",
            "Epoch 6/50, Loss: 1.3263\n",
            "Epoch 7/50, Loss: 1.3009\n",
            "Epoch 8/50, Loss: 1.2861\n",
            "Epoch 9/50, Loss: 1.2755\n",
            "Epoch 10/50, Loss: 1.2611\n",
            "Epoch 11/50, Loss: 1.2451\n",
            "Epoch 12/50, Loss: 1.2336\n",
            "Epoch 13/50, Loss: 1.2142\n",
            "Epoch 14/50, Loss: 1.2178\n",
            "Epoch 15/50, Loss: 1.2095\n",
            "Epoch 16/50, Loss: 1.1876\n",
            "Epoch 17/50, Loss: 1.1841\n",
            "Epoch 18/50, Loss: 1.1726\n",
            "Epoch 19/50, Loss: 1.1690\n",
            "Epoch 20/50, Loss: 1.1583\n",
            "Epoch 21/50, Loss: 1.1520\n",
            "Epoch 22/50, Loss: 1.1448\n",
            "Epoch 23/50, Loss: 1.1310\n",
            "Epoch 24/50, Loss: 1.1191\n",
            "Epoch 25/50, Loss: 1.1315\n",
            "Epoch 26/50, Loss: 1.1155\n",
            "Epoch 27/50, Loss: 1.0976\n",
            "Epoch 28/50, Loss: 1.0932\n",
            "Epoch 29/50, Loss: 1.0829\n",
            "Epoch 30/50, Loss: 1.0784\n",
            "Epoch 31/50, Loss: 1.0741\n",
            "Epoch 32/50, Loss: 1.0691\n",
            "Epoch 33/50, Loss: 1.0702\n",
            "Epoch 34/50, Loss: 1.0541\n",
            "Epoch 35/50, Loss: 1.0473\n",
            "Epoch 36/50, Loss: 1.0495\n",
            "Epoch 37/50, Loss: 1.0474\n",
            "Epoch 38/50, Loss: 1.0471\n",
            "Epoch 39/50, Loss: 1.0509\n",
            "Epoch 40/50, Loss: 1.0310\n",
            "Epoch 41/50, Loss: 1.0282\n",
            "Epoch 42/50, Loss: 1.0346\n",
            "Epoch 43/50, Loss: 1.0234\n",
            "Epoch 44/50, Loss: 1.0181\n",
            "Epoch 45/50, Loss: 1.0184\n",
            "Epoch 46/50, Loss: 1.0148\n",
            "Epoch 47/50, Loss: 1.0103\n",
            "Epoch 48/50, Loss: 1.0073\n",
            "Epoch 49/50, Loss: 1.0227\n",
            "Epoch 50/50, Loss: 0.9985\n",
            "Test Loss: 1.4230, Accuracy: 56.31%\n",
            "Training model with parameters: {'epochs': 50, 'kernel_size': 3, 'optimizer': 'Adam', 'pooling': 'avg'}\n",
            "Epoch 1/50, Loss: 1.8246\n",
            "Epoch 2/50, Loss: 1.6505\n",
            "Epoch 3/50, Loss: 1.5891\n",
            "Epoch 4/50, Loss: 1.5565\n",
            "Epoch 5/50, Loss: 1.5296\n",
            "Epoch 6/50, Loss: 1.5130\n",
            "Epoch 7/50, Loss: 1.5048\n",
            "Epoch 8/50, Loss: 1.4831\n",
            "Epoch 9/50, Loss: 1.4800\n",
            "Epoch 10/50, Loss: 1.4680\n",
            "Epoch 11/50, Loss: 1.4546\n",
            "Epoch 12/50, Loss: 1.3862\n",
            "Epoch 13/50, Loss: 1.3426\n",
            "Epoch 14/50, Loss: 1.3192\n",
            "Epoch 15/50, Loss: 1.2962\n",
            "Epoch 16/50, Loss: 1.2833\n",
            "Epoch 17/50, Loss: 1.2697\n",
            "Epoch 18/50, Loss: 1.2640\n",
            "Epoch 19/50, Loss: 1.2503\n",
            "Epoch 20/50, Loss: 1.2397\n",
            "Epoch 21/50, Loss: 1.2407\n",
            "Epoch 22/50, Loss: 1.2241\n",
            "Epoch 23/50, Loss: 1.2173\n",
            "Epoch 24/50, Loss: 1.2211\n",
            "Epoch 25/50, Loss: 1.2103\n",
            "Epoch 26/50, Loss: 1.1963\n",
            "Epoch 27/50, Loss: 1.1987\n",
            "Epoch 28/50, Loss: 1.2005\n",
            "Epoch 29/50, Loss: 1.1907\n",
            "Epoch 30/50, Loss: 1.1846\n",
            "Epoch 31/50, Loss: 1.1794\n",
            "Epoch 32/50, Loss: 1.1771\n",
            "Epoch 33/50, Loss: 1.1745\n",
            "Epoch 34/50, Loss: 1.1732\n",
            "Epoch 35/50, Loss: 1.1615\n",
            "Epoch 36/50, Loss: 1.1682\n",
            "Epoch 37/50, Loss: 1.1594\n",
            "Epoch 38/50, Loss: 1.1670\n",
            "Epoch 39/50, Loss: 1.1643\n",
            "Epoch 40/50, Loss: 1.1606\n",
            "Epoch 41/50, Loss: 1.1568\n",
            "Epoch 42/50, Loss: 1.1476\n",
            "Epoch 43/50, Loss: 1.1541\n",
            "Epoch 44/50, Loss: 1.1488\n",
            "Epoch 45/50, Loss: 1.1433\n",
            "Epoch 46/50, Loss: 1.1483\n",
            "Epoch 47/50, Loss: 1.1408\n",
            "Epoch 48/50, Loss: 1.1441\n",
            "Epoch 49/50, Loss: 1.1445\n",
            "Epoch 50/50, Loss: 1.1376\n",
            "Test Loss: 1.3472, Accuracy: 54.59%\n",
            "Training model with parameters: {'epochs': 50, 'kernel_size': 5, 'optimizer': 'SGD', 'pooling': 'max'}\n",
            "Epoch 1/50, Loss: 2.0077\n",
            "Epoch 2/50, Loss: 1.6111\n",
            "Epoch 3/50, Loss: 1.4405\n",
            "Epoch 4/50, Loss: 1.3346\n",
            "Epoch 5/50, Loss: 1.2484\n",
            "Epoch 6/50, Loss: 1.1708\n",
            "Epoch 7/50, Loss: 1.1034\n",
            "Epoch 8/50, Loss: 1.0434\n",
            "Epoch 9/50, Loss: 0.9880\n",
            "Epoch 10/50, Loss: 0.9401\n",
            "Epoch 11/50, Loss: 0.8899\n",
            "Epoch 12/50, Loss: 0.8496\n",
            "Epoch 13/50, Loss: 0.8089\n",
            "Epoch 14/50, Loss: 0.7708\n",
            "Epoch 15/50, Loss: 0.7361\n",
            "Epoch 16/50, Loss: 0.7012\n",
            "Epoch 17/50, Loss: 0.6683\n",
            "Epoch 18/50, Loss: 0.6323\n",
            "Epoch 19/50, Loss: 0.5987\n",
            "Epoch 20/50, Loss: 0.5668\n",
            "Epoch 21/50, Loss: 0.5365\n",
            "Epoch 22/50, Loss: 0.4993\n",
            "Epoch 23/50, Loss: 0.4690\n",
            "Epoch 24/50, Loss: 0.4382\n",
            "Epoch 25/50, Loss: 0.4035\n",
            "Epoch 26/50, Loss: 0.3763\n",
            "Epoch 27/50, Loss: 0.3455\n",
            "Epoch 28/50, Loss: 0.3159\n",
            "Epoch 29/50, Loss: 0.2850\n",
            "Epoch 30/50, Loss: 0.2546\n",
            "Epoch 31/50, Loss: 0.2303\n",
            "Epoch 32/50, Loss: 0.2030\n",
            "Epoch 33/50, Loss: 0.1795\n",
            "Epoch 34/50, Loss: 0.1563\n",
            "Epoch 35/50, Loss: 0.1336\n",
            "Epoch 36/50, Loss: 0.1110\n",
            "Epoch 37/50, Loss: 0.0978\n",
            "Epoch 38/50, Loss: 0.0802\n",
            "Epoch 39/50, Loss: 0.0611\n",
            "Epoch 40/50, Loss: 0.0495\n",
            "Epoch 41/50, Loss: 0.0378\n",
            "Epoch 42/50, Loss: 0.0287\n",
            "Epoch 43/50, Loss: 0.0236\n",
            "Epoch 44/50, Loss: 0.0176\n",
            "Epoch 45/50, Loss: 0.0142\n",
            "Epoch 46/50, Loss: 0.0120\n",
            "Epoch 47/50, Loss: 0.0104\n",
            "Epoch 48/50, Loss: 0.0093\n",
            "Epoch 49/50, Loss: 0.0080\n",
            "Epoch 50/50, Loss: 0.0071\n",
            "Test Loss: 1.7203, Accuracy: 71.54%\n",
            "Training model with parameters: {'epochs': 50, 'kernel_size': 5, 'optimizer': 'SGD', 'pooling': 'avg'}\n",
            "Epoch 1/50, Loss: 2.0981\n",
            "Epoch 2/50, Loss: 1.7510\n",
            "Epoch 3/50, Loss: 1.5830\n",
            "Epoch 4/50, Loss: 1.4760\n",
            "Epoch 5/50, Loss: 1.3922\n",
            "Epoch 6/50, Loss: 1.3270\n",
            "Epoch 7/50, Loss: 1.2764\n",
            "Epoch 8/50, Loss: 1.2293\n",
            "Epoch 9/50, Loss: 1.1893\n",
            "Epoch 10/50, Loss: 1.1499\n",
            "Epoch 11/50, Loss: 1.1140\n",
            "Epoch 12/50, Loss: 1.0789\n",
            "Epoch 13/50, Loss: 1.0479\n",
            "Epoch 14/50, Loss: 1.0142\n",
            "Epoch 15/50, Loss: 0.9836\n",
            "Epoch 16/50, Loss: 0.9533\n",
            "Epoch 17/50, Loss: 0.9237\n",
            "Epoch 18/50, Loss: 0.8950\n",
            "Epoch 19/50, Loss: 0.8673\n",
            "Epoch 20/50, Loss: 0.8410\n",
            "Epoch 21/50, Loss: 0.8126\n",
            "Epoch 22/50, Loss: 0.7843\n",
            "Epoch 23/50, Loss: 0.7599\n",
            "Epoch 24/50, Loss: 0.7320\n",
            "Epoch 25/50, Loss: 0.7068\n",
            "Epoch 26/50, Loss: 0.6816\n",
            "Epoch 27/50, Loss: 0.6571\n",
            "Epoch 28/50, Loss: 0.6329\n",
            "Epoch 29/50, Loss: 0.6076\n",
            "Epoch 30/50, Loss: 0.5850\n",
            "Epoch 31/50, Loss: 0.5593\n",
            "Epoch 32/50, Loss: 0.5362\n",
            "Epoch 33/50, Loss: 0.5118\n",
            "Epoch 34/50, Loss: 0.4873\n",
            "Epoch 35/50, Loss: 0.4628\n",
            "Epoch 36/50, Loss: 0.4401\n",
            "Epoch 37/50, Loss: 0.4145\n",
            "Epoch 38/50, Loss: 0.3937\n",
            "Epoch 39/50, Loss: 0.3673\n",
            "Epoch 40/50, Loss: 0.3449\n",
            "Epoch 41/50, Loss: 0.3219\n",
            "Epoch 42/50, Loss: 0.3030\n",
            "Epoch 43/50, Loss: 0.2802\n",
            "Epoch 44/50, Loss: 0.2561\n",
            "Epoch 45/50, Loss: 0.2372\n",
            "Epoch 46/50, Loss: 0.2186\n",
            "Epoch 47/50, Loss: 0.1980\n",
            "Epoch 48/50, Loss: 0.1806\n",
            "Epoch 49/50, Loss: 0.1646\n",
            "Epoch 50/50, Loss: 0.1471\n",
            "Test Loss: 1.4241, Accuracy: 67.70%\n",
            "Training model with parameters: {'epochs': 50, 'kernel_size': 5, 'optimizer': 'RMSProp', 'pooling': 'max'}\n",
            "Epoch 1/50, Loss: 31.0467\n",
            "Epoch 2/50, Loss: 2.1791\n",
            "Epoch 3/50, Loss: 1.9959\n",
            "Epoch 4/50, Loss: 1.9487\n",
            "Epoch 5/50, Loss: 1.7882\n",
            "Epoch 6/50, Loss: 1.6879\n",
            "Epoch 7/50, Loss: 1.6068\n",
            "Epoch 8/50, Loss: 1.5505\n",
            "Epoch 9/50, Loss: 1.4931\n",
            "Epoch 10/50, Loss: 1.4608\n",
            "Epoch 11/50, Loss: 1.4347\n",
            "Epoch 12/50, Loss: 1.4013\n",
            "Epoch 13/50, Loss: 1.3865\n",
            "Epoch 14/50, Loss: 1.3566\n",
            "Epoch 15/50, Loss: 1.3495\n",
            "Epoch 16/50, Loss: 1.3641\n",
            "Epoch 17/50, Loss: 1.3349\n",
            "Epoch 18/50, Loss: 1.3187\n",
            "Epoch 19/50, Loss: 1.3420\n",
            "Epoch 20/50, Loss: 1.3930\n",
            "Epoch 21/50, Loss: 1.3301\n",
            "Epoch 22/50, Loss: 1.2754\n",
            "Epoch 23/50, Loss: 1.2826\n",
            "Epoch 24/50, Loss: 1.2902\n",
            "Epoch 25/50, Loss: 1.3221\n",
            "Epoch 26/50, Loss: 1.5211\n",
            "Epoch 27/50, Loss: 1.1799\n",
            "Epoch 28/50, Loss: 0.9537\n",
            "Epoch 29/50, Loss: 0.8943\n",
            "Epoch 30/50, Loss: 0.8588\n",
            "Epoch 31/50, Loss: 0.8321\n",
            "Epoch 32/50, Loss: 0.8116\n",
            "Epoch 33/50, Loss: 0.7926\n",
            "Epoch 34/50, Loss: 0.7737\n",
            "Epoch 35/50, Loss: 0.7571\n",
            "Epoch 36/50, Loss: 0.7396\n",
            "Epoch 37/50, Loss: 0.7259\n",
            "Epoch 38/50, Loss: 0.7109\n",
            "Epoch 39/50, Loss: 0.6965\n",
            "Epoch 40/50, Loss: 0.6837\n",
            "Epoch 41/50, Loss: 0.6701\n",
            "Epoch 42/50, Loss: 0.6564\n",
            "Epoch 43/50, Loss: 0.6448\n",
            "Epoch 44/50, Loss: 0.6322\n",
            "Epoch 45/50, Loss: 0.6212\n",
            "Epoch 46/50, Loss: 0.6097\n",
            "Epoch 47/50, Loss: 0.5981\n",
            "Epoch 48/50, Loss: 0.5874\n",
            "Epoch 49/50, Loss: 0.5775\n",
            "Epoch 50/50, Loss: 0.5675\n",
            "Test Loss: 2.1301, Accuracy: 57.72%\n",
            "Training model with parameters: {'epochs': 50, 'kernel_size': 5, 'optimizer': 'RMSProp', 'pooling': 'avg'}\n",
            "Epoch 1/50, Loss: 10.6890\n",
            "Epoch 2/50, Loss: 2.0526\n",
            "Epoch 3/50, Loss: 1.7273\n",
            "Epoch 4/50, Loss: 1.5696\n",
            "Epoch 5/50, Loss: 1.4835\n",
            "Epoch 6/50, Loss: 1.4243\n",
            "Epoch 7/50, Loss: 1.3995\n",
            "Epoch 8/50, Loss: 1.3540\n",
            "Epoch 9/50, Loss: 1.3355\n",
            "Epoch 10/50, Loss: 1.2494\n",
            "Epoch 11/50, Loss: 1.2146\n",
            "Epoch 12/50, Loss: 1.2124\n",
            "Epoch 13/50, Loss: 1.1604\n",
            "Epoch 14/50, Loss: 1.3256\n",
            "Epoch 15/50, Loss: 1.1912\n",
            "Epoch 16/50, Loss: 1.0926\n",
            "Epoch 17/50, Loss: 1.1774\n",
            "Epoch 18/50, Loss: 1.0667\n",
            "Epoch 19/50, Loss: 1.1184\n",
            "Epoch 20/50, Loss: 1.0638\n",
            "Epoch 21/50, Loss: 1.0615\n",
            "Epoch 22/50, Loss: 1.0707\n",
            "Epoch 23/50, Loss: 1.0757\n",
            "Epoch 24/50, Loss: 1.0165\n",
            "Epoch 25/50, Loss: 0.9802\n",
            "Epoch 26/50, Loss: 0.9663\n",
            "Epoch 27/50, Loss: 1.8276\n",
            "Epoch 28/50, Loss: 1.1575\n",
            "Epoch 29/50, Loss: 1.4213\n",
            "Epoch 30/50, Loss: 3.0464\n",
            "Epoch 31/50, Loss: 1.3706\n",
            "Epoch 32/50, Loss: 0.9148\n",
            "Epoch 33/50, Loss: 0.6939\n",
            "Epoch 34/50, Loss: 0.6337\n",
            "Epoch 35/50, Loss: 0.5998\n",
            "Epoch 36/50, Loss: 0.5733\n",
            "Epoch 37/50, Loss: 0.5508\n",
            "Epoch 38/50, Loss: 0.5310\n",
            "Epoch 39/50, Loss: 0.5112\n",
            "Epoch 40/50, Loss: 0.4955\n",
            "Epoch 41/50, Loss: 0.4788\n",
            "Epoch 42/50, Loss: 0.4660\n",
            "Epoch 43/50, Loss: 0.4496\n",
            "Epoch 44/50, Loss: 0.4383\n",
            "Epoch 45/50, Loss: 0.4263\n",
            "Epoch 46/50, Loss: 0.4124\n",
            "Epoch 47/50, Loss: 0.4034\n",
            "Epoch 48/50, Loss: 0.3921\n",
            "Epoch 49/50, Loss: 0.3817\n",
            "Epoch 50/50, Loss: 0.3717\n",
            "Test Loss: 3.1250, Accuracy: 59.70%\n",
            "Training model with parameters: {'epochs': 50, 'kernel_size': 5, 'optimizer': 'Adam', 'pooling': 'max'}\n",
            "Epoch 1/50, Loss: 2.3218\n",
            "Epoch 2/50, Loss: 2.3035\n",
            "Epoch 3/50, Loss: 2.3035\n",
            "Epoch 4/50, Loss: 2.3037\n",
            "Epoch 5/50, Loss: 2.3035\n",
            "Epoch 6/50, Loss: 2.3035\n",
            "Epoch 7/50, Loss: 2.3031\n",
            "Epoch 8/50, Loss: 2.3027\n",
            "Epoch 9/50, Loss: 2.3027\n",
            "Epoch 10/50, Loss: 2.3027\n",
            "Epoch 11/50, Loss: 2.3027\n",
            "Epoch 12/50, Loss: 2.3027\n",
            "Epoch 13/50, Loss: 2.3026\n",
            "Epoch 14/50, Loss: 2.3026\n",
            "Epoch 15/50, Loss: 2.3026\n",
            "Epoch 16/50, Loss: 2.3026\n",
            "Epoch 17/50, Loss: 2.3026\n",
            "Epoch 18/50, Loss: 2.3026\n",
            "Epoch 19/50, Loss: 2.3026\n",
            "Epoch 20/50, Loss: 2.3026\n",
            "Epoch 21/50, Loss: 2.3026\n",
            "Epoch 22/50, Loss: 2.3026\n",
            "Epoch 23/50, Loss: 2.3026\n",
            "Epoch 24/50, Loss: 2.3026\n",
            "Epoch 25/50, Loss: 2.3026\n",
            "Epoch 26/50, Loss: 2.3026\n",
            "Epoch 27/50, Loss: 2.3026\n",
            "Epoch 28/50, Loss: 2.3026\n",
            "Epoch 29/50, Loss: 2.3026\n",
            "Epoch 30/50, Loss: 2.3026\n",
            "Epoch 31/50, Loss: 2.3026\n",
            "Epoch 32/50, Loss: 2.3026\n",
            "Epoch 33/50, Loss: 2.3026\n",
            "Epoch 34/50, Loss: 2.3026\n",
            "Epoch 35/50, Loss: 2.3026\n",
            "Epoch 36/50, Loss: 2.3026\n",
            "Epoch 37/50, Loss: 2.3026\n",
            "Early stopping triggered\n",
            "Test Loss: 2.3026, Accuracy: 10.00%\n",
            "Training model with parameters: {'epochs': 50, 'kernel_size': 5, 'optimizer': 'Adam', 'pooling': 'avg'}\n",
            "Epoch 1/50, Loss: 2.3109\n",
            "Epoch 2/50, Loss: 2.3035\n",
            "Epoch 3/50, Loss: 2.3037\n",
            "Epoch 4/50, Loss: 2.3037\n",
            "Epoch 5/50, Loss: 2.3036\n",
            "Epoch 6/50, Loss: 2.3037\n",
            "Epoch 7/50, Loss: 2.3028\n",
            "Epoch 8/50, Loss: 2.3027\n",
            "Epoch 9/50, Loss: 2.3027\n",
            "Epoch 10/50, Loss: 2.3027\n",
            "Epoch 11/50, Loss: 2.3027\n",
            "Epoch 12/50, Loss: 2.3026\n",
            "Epoch 13/50, Loss: 2.3026\n",
            "Epoch 14/50, Loss: 2.3026\n",
            "Epoch 15/50, Loss: 2.3026\n",
            "Epoch 16/50, Loss: 2.3026\n",
            "Epoch 17/50, Loss: 2.3026\n",
            "Epoch 18/50, Loss: 2.3026\n",
            "Epoch 19/50, Loss: 2.3026\n",
            "Epoch 20/50, Loss: 2.3026\n",
            "Epoch 21/50, Loss: 2.3026\n",
            "Epoch 22/50, Loss: 2.3026\n",
            "Epoch 23/50, Loss: 2.3026\n",
            "Epoch 24/50, Loss: 2.3026\n",
            "Epoch 25/50, Loss: 2.3026\n",
            "Epoch 26/50, Loss: 2.3026\n",
            "Epoch 27/50, Loss: 2.3026\n",
            "Epoch 28/50, Loss: 2.3026\n",
            "Epoch 29/50, Loss: 2.3026\n",
            "Epoch 30/50, Loss: 2.3026\n",
            "Epoch 31/50, Loss: 2.3026\n",
            "Early stopping triggered\n",
            "Test Loss: 2.3026, Accuracy: 10.00%\n",
            "Training model with parameters: {'epochs': 50, 'kernel_size': 7, 'optimizer': 'SGD', 'pooling': 'max'}\n",
            "Epoch 1/50, Loss: 1.9604\n",
            "Epoch 2/50, Loss: 1.5667\n",
            "Epoch 3/50, Loss: 1.4041\n",
            "Epoch 4/50, Loss: 1.2911\n",
            "Epoch 5/50, Loss: 1.1947\n",
            "Epoch 6/50, Loss: 1.1109\n",
            "Epoch 7/50, Loss: 1.0411\n",
            "Epoch 8/50, Loss: 0.9779\n",
            "Epoch 9/50, Loss: 0.9279\n",
            "Epoch 10/50, Loss: 0.8825\n",
            "Epoch 11/50, Loss: 0.8372\n",
            "Epoch 12/50, Loss: 0.7980\n",
            "Epoch 13/50, Loss: 0.7585\n",
            "Epoch 14/50, Loss: 0.7209\n",
            "Epoch 15/50, Loss: 0.6827\n",
            "Epoch 16/50, Loss: 0.6464\n",
            "Epoch 17/50, Loss: 0.6084\n",
            "Epoch 18/50, Loss: 0.5759\n",
            "Epoch 19/50, Loss: 0.5413\n",
            "Epoch 20/50, Loss: 0.5080\n",
            "Epoch 21/50, Loss: 0.4740\n",
            "Epoch 22/50, Loss: 0.4386\n",
            "Epoch 23/50, Loss: 0.4069\n",
            "Epoch 24/50, Loss: 0.3738\n",
            "Epoch 25/50, Loss: 0.3386\n",
            "Epoch 26/50, Loss: 0.3098\n",
            "Epoch 27/50, Loss: 0.2789\n",
            "Epoch 28/50, Loss: 0.2496\n",
            "Epoch 29/50, Loss: 0.2226\n",
            "Epoch 30/50, Loss: 0.1954\n",
            "Epoch 31/50, Loss: 0.1704\n",
            "Epoch 32/50, Loss: 0.1478\n",
            "Epoch 33/50, Loss: 0.1212\n",
            "Epoch 34/50, Loss: 0.1002\n",
            "Epoch 35/50, Loss: 0.0842\n",
            "Epoch 36/50, Loss: 0.0696\n",
            "Epoch 37/50, Loss: 0.0535\n",
            "Epoch 38/50, Loss: 0.0456\n",
            "Epoch 39/50, Loss: 0.0308\n",
            "Epoch 40/50, Loss: 0.0232\n",
            "Epoch 41/50, Loss: 0.0179\n",
            "Epoch 42/50, Loss: 0.0141\n",
            "Epoch 43/50, Loss: 0.0123\n",
            "Epoch 44/50, Loss: 0.0105\n",
            "Epoch 45/50, Loss: 0.0088\n",
            "Epoch 46/50, Loss: 0.0078\n",
            "Epoch 47/50, Loss: 0.0070\n",
            "Epoch 48/50, Loss: 0.0063\n",
            "Epoch 49/50, Loss: 0.0057\n",
            "Epoch 50/50, Loss: 0.0051\n",
            "Test Loss: 1.7011, Accuracy: 72.74%\n",
            "Training model with parameters: {'epochs': 50, 'kernel_size': 7, 'optimizer': 'SGD', 'pooling': 'avg'}\n",
            "Epoch 1/50, Loss: 2.0730\n",
            "Epoch 2/50, Loss: 1.6998\n",
            "Epoch 3/50, Loss: 1.5415\n",
            "Epoch 4/50, Loss: 1.4418\n",
            "Epoch 5/50, Loss: 1.3714\n",
            "Epoch 6/50, Loss: 1.3155\n",
            "Epoch 7/50, Loss: 1.2663\n",
            "Epoch 8/50, Loss: 1.2196\n",
            "Epoch 9/50, Loss: 1.1718\n",
            "Epoch 10/50, Loss: 1.1252\n",
            "Epoch 11/50, Loss: 1.0826\n",
            "Epoch 12/50, Loss: 1.0403\n",
            "Epoch 13/50, Loss: 1.0032\n",
            "Epoch 14/50, Loss: 0.9641\n",
            "Epoch 15/50, Loss: 0.9275\n",
            "Epoch 16/50, Loss: 0.8923\n",
            "Epoch 17/50, Loss: 0.8616\n",
            "Epoch 18/50, Loss: 0.8269\n",
            "Epoch 19/50, Loss: 0.7976\n",
            "Epoch 20/50, Loss: 0.7669\n",
            "Epoch 21/50, Loss: 0.7367\n",
            "Epoch 22/50, Loss: 0.7073\n",
            "Epoch 23/50, Loss: 0.6802\n",
            "Epoch 24/50, Loss: 0.6504\n",
            "Epoch 25/50, Loss: 0.6222\n",
            "Epoch 26/50, Loss: 0.5946\n",
            "Epoch 27/50, Loss: 0.5671\n",
            "Epoch 28/50, Loss: 0.5401\n",
            "Epoch 29/50, Loss: 0.5152\n",
            "Epoch 30/50, Loss: 0.4843\n",
            "Epoch 31/50, Loss: 0.4604\n",
            "Epoch 32/50, Loss: 0.4332\n",
            "Epoch 33/50, Loss: 0.4089\n",
            "Epoch 34/50, Loss: 0.3852\n",
            "Epoch 35/50, Loss: 0.3586\n",
            "Epoch 36/50, Loss: 0.3324\n",
            "Epoch 37/50, Loss: 0.3069\n",
            "Epoch 38/50, Loss: 0.2853\n",
            "Epoch 39/50, Loss: 0.2601\n",
            "Epoch 40/50, Loss: 0.2387\n",
            "Epoch 41/50, Loss: 0.2150\n",
            "Epoch 42/50, Loss: 0.1931\n",
            "Epoch 43/50, Loss: 0.1746\n",
            "Epoch 44/50, Loss: 0.1592\n",
            "Epoch 45/50, Loss: 0.1394\n",
            "Epoch 46/50, Loss: 0.1207\n",
            "Epoch 47/50, Loss: 0.1023\n",
            "Epoch 48/50, Loss: 0.0922\n",
            "Epoch 49/50, Loss: 0.0770\n",
            "Epoch 50/50, Loss: 0.0658\n",
            "Test Loss: 1.6038, Accuracy: 68.68%\n",
            "Training model with parameters: {'epochs': 50, 'kernel_size': 7, 'optimizer': 'RMSProp', 'pooling': 'max'}\n",
            "Epoch 1/50, Loss: 36.7742\n",
            "Epoch 2/50, Loss: 2.3038\n",
            "Epoch 3/50, Loss: 2.3040\n",
            "Epoch 4/50, Loss: 2.3036\n",
            "Epoch 5/50, Loss: 2.3035\n",
            "Epoch 6/50, Loss: 2.3036\n",
            "Epoch 7/50, Loss: 2.3036\n",
            "Epoch 8/50, Loss: 2.3038\n",
            "Epoch 9/50, Loss: 2.3035\n",
            "Epoch 10/50, Loss: 2.3031\n",
            "Epoch 11/50, Loss: 2.3027\n",
            "Epoch 12/50, Loss: 2.3027\n",
            "Epoch 13/50, Loss: 2.3027\n",
            "Epoch 14/50, Loss: 2.3027\n",
            "Epoch 15/50, Loss: 2.3027\n",
            "Epoch 16/50, Loss: 2.3026\n",
            "Epoch 17/50, Loss: 2.3026\n",
            "Epoch 18/50, Loss: 2.3026\n",
            "Epoch 19/50, Loss: 2.3026\n",
            "Epoch 20/50, Loss: 2.3026\n",
            "Epoch 21/50, Loss: 2.3026\n",
            "Epoch 22/50, Loss: 2.3026\n",
            "Epoch 23/50, Loss: 2.3026\n",
            "Epoch 24/50, Loss: 2.3026\n",
            "Epoch 25/50, Loss: 2.3026\n",
            "Epoch 26/50, Loss: 2.3026\n",
            "Epoch 27/50, Loss: 2.3026\n",
            "Epoch 28/50, Loss: 2.3026\n",
            "Epoch 29/50, Loss: 2.3026\n",
            "Epoch 30/50, Loss: 2.3026\n",
            "Epoch 31/50, Loss: 2.3026\n",
            "Epoch 32/50, Loss: 2.3026\n",
            "Epoch 33/50, Loss: 2.3026\n",
            "Epoch 34/50, Loss: 2.3026\n",
            "Epoch 35/50, Loss: 2.3026\n",
            "Epoch 36/50, Loss: 2.3026\n",
            "Epoch 37/50, Loss: 2.3026\n",
            "Epoch 38/50, Loss: 2.3026\n",
            "Epoch 39/50, Loss: 2.3026\n",
            "Early stopping triggered\n",
            "Test Loss: 2.3026, Accuracy: 10.00%\n",
            "Training model with parameters: {'epochs': 50, 'kernel_size': 7, 'optimizer': 'RMSProp', 'pooling': 'avg'}\n",
            "Epoch 1/50, Loss: 34.0574\n",
            "Epoch 2/50, Loss: 2.4388\n",
            "Epoch 3/50, Loss: 2.5102\n",
            "Epoch 4/50, Loss: 1.9483\n",
            "Epoch 5/50, Loss: 1.8809\n",
            "Epoch 6/50, Loss: 1.7963\n",
            "Epoch 7/50, Loss: 2.4977\n",
            "Epoch 8/50, Loss: 1.7567\n",
            "Epoch 9/50, Loss: 1.6379\n",
            "Epoch 10/50, Loss: 2.3437\n",
            "Epoch 11/50, Loss: 1.6031\n",
            "Epoch 12/50, Loss: 1.5568\n",
            "Epoch 13/50, Loss: 1.5495\n",
            "Epoch 14/50, Loss: 1.5380\n",
            "Epoch 15/50, Loss: 1.4817\n",
            "Epoch 16/50, Loss: 1.4310\n",
            "Epoch 17/50, Loss: 1.4202\n",
            "Epoch 18/50, Loss: 1.4496\n",
            "Epoch 19/50, Loss: 1.3670\n",
            "Epoch 20/50, Loss: 1.3636\n",
            "Epoch 21/50, Loss: 1.3326\n",
            "Epoch 22/50, Loss: 1.3380\n",
            "Epoch 23/50, Loss: 1.3081\n",
            "Epoch 24/50, Loss: 1.3014\n",
            "Epoch 25/50, Loss: 1.2854\n",
            "Epoch 26/50, Loss: 1.2654\n",
            "Epoch 27/50, Loss: 1.2530\n",
            "Epoch 28/50, Loss: 1.2590\n",
            "Epoch 29/50, Loss: 1.2336\n",
            "Epoch 30/50, Loss: 1.2200\n",
            "Epoch 31/50, Loss: 1.2261\n",
            "Epoch 32/50, Loss: 1.1883\n",
            "Epoch 33/50, Loss: 1.1789\n",
            "Epoch 34/50, Loss: 1.1654\n",
            "Epoch 35/50, Loss: 1.1702\n",
            "Epoch 36/50, Loss: 1.1812\n",
            "Epoch 37/50, Loss: 1.1581\n",
            "Epoch 38/50, Loss: 1.1226\n",
            "Epoch 39/50, Loss: 1.1188\n",
            "Epoch 40/50, Loss: 1.1143\n",
            "Epoch 41/50, Loss: 1.1101\n",
            "Epoch 42/50, Loss: 1.1046\n",
            "Epoch 43/50, Loss: 1.0842\n",
            "Epoch 44/50, Loss: 1.0839\n",
            "Epoch 45/50, Loss: 1.0697\n",
            "Epoch 46/50, Loss: 1.0869\n",
            "Epoch 47/50, Loss: 1.0511\n",
            "Epoch 48/50, Loss: 1.0443\n",
            "Epoch 49/50, Loss: 1.0349\n",
            "Epoch 50/50, Loss: 1.0312\n",
            "Test Loss: 1.9764, Accuracy: 48.62%\n",
            "Training model with parameters: {'epochs': 50, 'kernel_size': 7, 'optimizer': 'Adam', 'pooling': 'max'}\n",
            "Epoch 1/50, Loss: 2.3433\n",
            "Epoch 2/50, Loss: 2.3035\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-268d37f0fdcf>\u001b[0m in \u001b[0;36m<cell line: 13>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;31m# Training model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0mtrain_losses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheduler\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscheduler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'epochs'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m     \u001b[0mend_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-8-68a54f3ea01f>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, train_loader, optimizer, criterion, scheduler, early_stop_patience, epochs)\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mepoch_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m             \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    699\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    700\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 701\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    702\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m             if (\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    755\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    756\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 757\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    758\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    759\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     50\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     50\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/datasets/cifar.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_transform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, pic)\u001b[0m\n\u001b[1;32m    135\u001b[0m             \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mConverted\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \"\"\"\n\u001b[0;32m--> 137\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py\u001b[0m in \u001b[0;36mto_tensor\u001b[0;34m(pic)\u001b[0m\n\u001b[1;32m    170\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"1\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m255\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mF_pil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_image_num_channels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m     \u001b[0;31m# put it from HWC to CHW format\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}